@online{abbasQuantumBackpropagationInformation2023,
  title = {On Quantum Backpropagation, Information Reuse, and Cheating Measurement Collapse},
  author = {Abbas, Amira and King, Robbie and Huang, Hsin-Yuan and Huggins, William J. and Movassagh, Ramis and Gilboa, Dar and McClean, Jarrod R.},
  date = {2023-05-22},
  eprint = {2305.13362},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/2305.13362},
  urldate = {2024-05-05},
  abstract = {The success of modern deep learning hinges on the ability to train neural networks at scale. Through clever reuse of intermediate information, backpropagation facilitates training through gradient computation at a total cost roughly proportional to running the function, rather than incurring an additional factor proportional to the number of parameters – which can now be in the trillions. Naively, one expects that quantum measurement collapse entirely rules out the reuse of quantum information as in backpropagation. But recent developments in shadow tomography, which assumes access to multiple copies of a quantum state, have challenged that notion. Here, we investigate whether parameterized quantum models can train as efficiently as classical neural networks. We show that achieving backpropagation scaling is impossible without access to multiple copies of a state. With this added ability, we introduce an algorithm with foundations in shadow tomography that matches backpropagation scaling in quantum resources while reducing classical auxiliary computational costs to open problems in shadow tomography. These results highlight the nuance of reusing quantum information for practical purposes and clarify the unique difficulties in training large quantum models, which could alter the course of quantum machine learning.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Quantum Physics},
  file = {/Users/eric/Zotero/storage/XM5S7VYL/Abbas et al. - 2023 - On quantum backpropagation, information reuse, and.pdf}
}

@online{abbasQuantumOptimizationPotential2023,
  title = {Quantum {{Optimization}}: {{Potential}}, {{Challenges}}, and the {{Path Forward}}},
  shorttitle = {Quantum {{Optimization}}},
  author = {Abbas, Amira and Ambainis, Andris and Augustino, Brandon and Bärtschi, Andreas and Buhrman, Harry and Coffrin, Carleton and Cortiana, Giorgio and Dunjko, Vedran and Egger, Daniel J. and Elmegreen, Bruce G. and Franco, Nicola and Fratini, Filippo and Fuller, Bryce and Gacon, Julien and Gonciulea, Constantin and Gribling, Sander and Gupta, Swati and Hadfield, Stuart and Heese, Raoul and Kircher, Gerhard and Kleinert, Thomas and Koch, Thorsten and Korpas, Georgios and Lenk, Steve and Marecek, Jakub and Markov, Vanio and Mazzola, Guglielmo and Mensa, Stefano and Mohseni, Naeimeh and Nannicini, Giacomo and O'Meara, Corey and Tapia, Elena Peña and Pokutta, Sebastian and Proissl, Manuel and Rebentrost, Patrick and Sahin, Emre and Symons, Benjamin C. B. and Tornow, Sabine and Valls, Victor and Woerner, Stefan and Wolf-Bauwens, Mira L. and Yard, Jon and Yarkoni, Sheir and Zechiel, Dirk and Zhuk, Sergiy and Zoufal, Christa},
  date = {2023-12-04},
  eprint = {2312.02279},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/2312.02279},
  urldate = {2024-04-17},
  abstract = {Recent advances in quantum computers are demonstrating the ability to solve problems at a scale beyond brute force classical simulation. As such, a widespread interest in quantum algorithms has developed in many areas, with optimization being one of the most pronounced domains. Across computer science and physics, there are a number of algorithmic approaches, often with little linkage. This is further complicated by the fragmented nature of the field of mathematical optimization, where major classes of optimization problems, such as combinatorial optimization, convex optimization, non-convex optimization, and stochastic extensions, have devoted communities. With these aspects in mind, this work draws on multiple approaches to study quantum optimization. Provably exact versus heuristic settings are first explained using computational complexity theory - highlighting where quantum advantage is possible in each context. Then, the core building blocks for quantum optimization algorithms are outlined to subsequently define prominent problem classes and identify key open questions that, if answered, will advance the field. The effects of scaling relevant problems on noisy quantum devices are also outlined in detail, alongside meaningful benchmarking problems. We underscore the importance of benchmarking by proposing clear metrics to conduct appropriate comparisons with classical optimization techniques. Lastly, we highlight two domains - finance and sustainability - as rich sources of optimization problems that could be used to benchmark, and eventually validate, the potential real-world impact of quantum optimization.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Mathematics - Optimization and Control,Quantum Physics},
  file = {/Users/eric/Zotero/storage/KB8TXQQU/Abbas et al. - 2023 - Quantum Optimization Potential, Challenges, and t.pdf}
}

@online{apersQuantumSpeedupGraph2023,
  title = {Quantum {{Speedup}} for {{Graph Sparsification}}, {{Cut Approximation}} and {{Laplacian Solving}}},
  author = {Apers, Simon and family=Wolf, given=Ronald, prefix=de, useprefix=true},
  date = {2023-05-08},
  eprint = {1911.07306},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/1911.07306},
  urldate = {2024-05-04},
  abstract = {Graph sparsification underlies a large number of algorithms, ranging from approximation algorithms for cut problems to solvers for linear systems in the graph Laplacian. In its strongest form, “spectral sparsification” reduces the number of edges to near-linear in the number of nodes, while approximately preserving the cut and spectral structure of the graph. In this work we demonstrate a polynomial quantum speedup for spectral sparsification and many of its applications. In particular, we give a quantum algorithm that, given a weighted graph with n nod√es and m edges, outputs a classical description of an -spectral sparsifier in sublinear time O( mn/ ). This contrasts with the optimal classical complexity O(m). We also prove that our quantum algorithm is optimal up to polylog-factors. The algorithm builds on a string of existing results on sparsification, graph spanners, quantum algorithms for shortest paths, and efficient constructions for k-wise independent random strings. Our algorithm implies a quantum speedup for solving Laplacian systems and for approximating a range of cut problems such as min cut and sparsest cut.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computational Complexity,Computer Science - Data Structures and Algorithms,Quantum Physics},
  file = {/Users/eric/Zotero/storage/5KTRVJDS/Apers and de Wolf - 2023 - Quantum Speedup for Graph Sparsification, Cut Appr.pdf}
}

@online{apersQuantumSpeedupsLinear2024,
  title = {Quantum Speedups for Linear Programming via Interior Point Methods},
  author = {Apers, Simon and Gribling, Sander},
  date = {2024-04-11},
  eprint = {2311.03215},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/2311.03215},
  urldate = {2024-05-03},
  abstract = {We describe a quantum algorithm based on an interior point method for solving a linear program with \$n\$ inequality constraints on \$d\$ variables. The algorithm explicitly returns a feasible solution that is \$\textbackslash varepsilon\$-close to optimal, and runs in time \$\textbackslash sqrt\{n\} \textbackslash cdot \textbackslash mathrm\{poly\}(d,\textbackslash log(n),\textbackslash log(1/\textbackslash varepsilon))\$ which is sublinear for tall linear programs (i.e., \$n \textbackslash gg d\$). Our algorithm speeds up the Newton step in the state-of-the-art interior point method of Lee and Sidford [FOCS\textasciitilde '14]. This requires us to efficiently approximate the Hessian and gradient of the barrier function, and these are our main contributions. To approximate the Hessian, we describe a quantum algorithm for the \textbackslash emph\{spectral approximation\} of \$A\textasciicircum T A\$ for a tall matrix \$A \textbackslash in \textbackslash mathbb R\textasciicircum\{n \textbackslash times d\}\$. The algorithm uses leverage score sampling in combination with Grover search, and returns a \$\textbackslash delta\$-approximation by making \$O(\textbackslash sqrt\{nd\}/\textbackslash delta)\$ row queries to \$A\$. This generalizes an earlier quantum speedup for graph sparsification by Apers and de Wolf\textasciitilde [FOCS\textasciitilde '20]. To approximate the gradient, we use a recent quantum algorithm for multivariate mean estimation by Cornelissen, Hamoudi and Jerbi [STOC '22]. While a naive implementation introduces a dependence on the condition number of the Hessian, we avoid this by pre-conditioning our random variable using our quantum algorithm for spectral approximation.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Optimization and Control,Quantum Physics},
  file = {/Users/eric/Zotero/storage/GLU5E3Y7/Apers and Gribling - 2024 - Quantum speedups for linear programming via interi.pdf}
}

@online{augustinoQuantumCentralPath2023,
  title = {A Quantum Central Path Algorithm for Linear Optimization},
  author = {Augustino, Brandon and Leng, Jiaqi and Nannicini, Giacomo and Terlaky, Tamás and Wu, Xiaodi},
  date = {2023-11-07},
  eprint = {2311.03977},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/2311.03977},
  urldate = {2024-05-03},
  abstract = {We propose a novel quantum algorithm for solving linear optimization problems by quantummechanical simulation of the central path. While interior point methods follow the central path with an iterative algorithm that works with successive linearizations of the perturbed KKT conditions, we perform a single simulation working directly with the nonlinear complementarity equations. Combining our approach with iterative refinement techniques, we obtain an exact solution to a linear optimization problem involving m constraints and n variables using at most O ((m + n)nnz(A)κ(M)L · polylog (m, n, κ(M))) elementary gates and O (nnz(A)L) classical arithmetic operations, where nnz(A) is the total number of non-zero elements found in the constraint matrix, L denotes binary input length of the problem data, and κ(M) is a condition number that depends only on the problem data.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Optimization and Control,Quantum Physics},
  file = {/Users/eric/Zotero/storage/WLKEW74B/Augustino et al. - 2023 - A quantum central path algorithm for linear optimi.pdf}
}

@book{boydConvexOptimization2004,
  title = {Convex Optimization},
  author = {Boyd, Stephen P. and Vandenberghe, Lieven},
  date = {2004},
  publisher = {Cambridge University Press},
  location = {Cambridge, UK ; New York},
  isbn = {978-0-521-83378-3},
  langid = {english},
  pagetotal = {716},
  keywords = {Convex functions,Mathematical optimization},
  file = {/Users/eric/Zotero/storage/9ZFAX7EM/Boyd and Vandenberghe - 2004 - Convex optimization.pdf}
}

@online{brandaoQuantumSDPSolvers2019,
  title = {Quantum {{SDP Solvers}}: {{Large Speed-ups}}, {{Optimality}}, and {{Applications}} to {{Quantum Learning}}},
  shorttitle = {Quantum {{SDP Solvers}}},
  author = {Brandão, Fernando G. S. L. and Kalev, Amir and Li, Tongyang and Lin, Cedric Yen-Yu and Svore, Krysta M. and Wu, Xiaodi},
  date = {2019-04-22},
  eprint = {1710.02581},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/1710.02581},
  urldate = {2024-05-03},
  abstract = {We give two quantum algorithms for solving semidefinite programs (SDPs) providing quantum speed-ups. We consider SDP instances with \$m\$ constraint matrices, each of dimension \$n\$, rank at most \$r\$, and sparsity \$s\$. The first algorithm assumes access to an oracle to the matrices at unit cost. We show that it has run time \$\textbackslash tilde\{O\}(s\textasciicircum 2(\textbackslash sqrt\{m\}\textbackslash epsilon\textasciicircum\{-10\}+\textbackslash sqrt\{n\}\textbackslash epsilon\textasciicircum\{-12\}))\$, with \$\textbackslash epsilon\$ the error of the solution. This gives an optimal dependence in terms of \$m, n\$ and quadratic improvement over previous quantum algorithms when \$m\textbackslash approx n\$. The second algorithm assumes a fully quantum input model in which the matrices are given as quantum states. We show that its run time is \$\textbackslash tilde\{O\}(\textbackslash sqrt\{m\}+\textbackslash text\{poly\}(r))\textbackslash cdot\textbackslash text\{poly\}(\textbackslash log m,\textbackslash log n,B,\textbackslash epsilon\textasciicircum\{-1\})\$, with \$B\$ an upper bound on the trace-norm of all input matrices. In particular the complexity depends only poly-logarithmically in \$n\$ and polynomially in \$r\$. We apply the second SDP solver to learn a good description of a quantum state with respect to a set of measurements: Given \$m\$ measurements and a supply of copies of an unknown state \$\textbackslash rho\$ with rank at most \$r\$, we show we can find in time \$\textbackslash sqrt\{m\}\textbackslash cdot\textbackslash text\{poly\}(\textbackslash log m,\textbackslash log n,r,\textbackslash epsilon\textasciicircum\{-1\})\$ a description of the state as a quantum circuit preparing a density matrix which has the same expectation values as \$\textbackslash rho\$ on the \$m\$ measurements, up to error \$\textbackslash epsilon\$. The density matrix obtained is an approximation to the maximum entropy state consistent with the measurement data considered in Jaynes' principle from statistical mechanics. As in previous work, we obtain our algorithm by "quantizing" classical SDP solvers based on the matrix multiplicative weight method. One of our main technical contributions is a quantum Gibbs state sampler for low-rank Hamiltonians with a poly-logarithmic dependence on its dimension, which could be of independent interest.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Data Structures and Algorithms,Quantum Physics},
  file = {/Users/eric/Zotero/storage/9M7DYMFM/Brandão et al. - 2019 - Quantum SDP Solvers Large Speed-ups, Optimality, .pdf}
}

@online{cohenEll_pRowSampling2014,
  title = {\$\textbackslash ell\_p\$ {{Row Sampling}} by {{Lewis Weights}}},
  author = {Cohen, Michael B. and Peng, Richard},
  date = {2014-12-01},
  eprint = {1412.0588},
  eprinttype = {arxiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/1412.0588},
  urldate = {2024-05-03},
  abstract = {We give a simple algorithm to efficiently sample the rows of a matrix while preserving the p-norms of its product with vectors. Given an n-by-d matrix A, we find with high probability and in input sparsity time an A′ consisting of about d log d rescaled rows of A such that Ax 1 is close to A′x 1 for all vectors x . We also show similar results for all ℓp that give nearly optimal sample bounds in input sparsity time. Our results are based on sampling by “Lewis weights”, which can be viewed as statistical leverage scores of a reweighted matrix. We also give an elementary proof of the guarantees of this sampling process for ℓ1.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Probability},
  file = {/Users/eric/Zotero/storage/GJ94WMX4/Cohen and Peng - 2014 - $ell_p$ Row Sampling by Lewis Weights.pdf}
}

@online{cohenUniformSamplingMatrix2014,
  title = {Uniform {{Sampling}} for {{Matrix Approximation}}},
  author = {Cohen, Michael B. and Lee, Yin Tat and Musco, Cameron and Musco, Christopher and Peng, Richard and Sidford, Aaron},
  date = {2014-08-21},
  eprint = {1408.5099},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1408.5099},
  urldate = {2024-05-04},
  abstract = {Random sampling has become a critical tool in solving massive matrix problems. For linear regression, a small, manageable set of data rows can be randomly selected to approximate a tall, skinny data matrix, improving processing time significantly. For theoretical performance guarantees, each row must be sampled with probability proportional to its statistical leverage score. Unfortunately, leverage scores are difficult to compute. A simple alternative is to sample rows uniformly at random. While this often works, uniform sampling will eliminate critical row information for many natural instances.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/eric/Zotero/storage/TAPIHQ53/Cohen et al. - 2014 - Uniform Sampling for Matrix Approximation.pdf}
}

@inproceedings{cornelissenNearOptimalQuantumAlgorithms2022,
  title = {Near-{{Optimal Quantum Algorithms}} for {{Multivariate Mean Estimation}}},
  booktitle = {Proceedings of the 54th {{Annual ACM SIGACT Symposium}} on {{Theory}} of {{Computing}}},
  author = {Cornelissen, Arjan and Hamoudi, Yassine and Jerbi, Sofiene},
  date = {2022-06-09},
  eprint = {2111.09787},
  eprinttype = {arxiv},
  eprintclass = {quant-ph, stat},
  pages = {33--43},
  doi = {10.1145/3519935.3520045},
  url = {http://arxiv.org/abs/2111.09787},
  urldate = {2024-05-04},
  abstract = {We propose the first near-optimal quantum algorithm for estimating in Euclidean norm the mean of a vector-valued random variable with finite mean and covariance. Our result aims at extending the theory of multivariate sub-Gaussian estimators [LM19a] to the quantum setting. Unlike classically, where any univariate estimator can be turned into a multivariate estimator with at most a logarithmic overhead in the dimension, no similar result can be proved in the quantum setting. Indeed, Heinrich [Hei04] ruled out the existence of a quantum advantage for the mean estimation problem when the sample complexity is smaller than the dimension. Our main result is to show that, outside this low-precision regime, there does exist a quantum estimator that outperforms any classical estimator. More precisely, we prove that the approximation error can be decreased by a factor of about the square root of the ratio between the dimension and the sample complexity. Our approach is substantially more involved than in the univariate setting, where most quantum estimators rely only on phase estimation. We exploit a variety of additional algorithmic techniques such as linear amplitude amplification, the Bernstein-Vazirani algorithm, and quantum singular value transformation. Our analysis is also deeply rooted in proving concentration inequalities for multivariate truncated statistics. We develop our quantum estimators in two different input models that showed up in the literature before. The first one provides coherent access to the binary representation of the random variable and it encompasses the classical setting. In the second model, the random variable is directly encoded into the phases of quantum registers. This model arises naturally in many quantum algorithms but it is often incomparable to having classical samples. We adapt our techniques to these two settings and we show that the second model is strictly weaker than the other one for solving the mean estimation problem. Finally, we describe several applications of our algorithms, notably in measuring the expectation values of commuting observables and in the field of machine learning.},
  langid = {english},
  keywords = {Computer Science - Computational Complexity,Computer Science - Data Structures and Algorithms,Mathematics - Statistics Theory,Quantum Physics,Statistics - Machine Learning},
  file = {/Users/eric/Zotero/storage/MEJVIQL5/Cornelissen et al. - 2022 - Near-Optimal Quantum Algorithms for Multivariate M.pdf}
}

@article{freundIntroductionSemidefiniteProgramming,
  title = {Introduction to {{Semideﬁnite Programming}} ({{SDP}})},
  author = {Freund, Robert M},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/eric/Zotero/storage/AHL2AZZW/Freund - Introduction to Semideﬁnite Programming (SDP).pdf}
}

@article{giovannettiQuantumRandomAccess2008,
  title = {Quantum Random Access Memory},
  author = {Giovannetti, Vittorio and Lloyd, Seth and Maccone, Lorenzo},
  date = {2008-04-21},
  journaltitle = {Phys. Rev. Lett.},
  volume = {100},
  number = {16},
  eprint = {0708.1879},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  pages = {160501},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.100.160501},
  url = {http://arxiv.org/abs/0708.1879},
  urldate = {2024-05-04},
  abstract = {A random access memory (RAM) uses n bits to randomly address N=2\textasciicircum n distinct memory cells. A quantum random access memory (qRAM) uses n qubits to address any quantum superposition of N memory cells. We present an architecture that exponentially reduces the requirements for a memory call: O(log N) switches need be thrown instead of the N used in conventional (classical or quantum) RAM designs. This yields a more robust qRAM algorithm, as it in general requires entanglement among exponentially less gates, and leads to an exponential decrease in the power needed for addressing. A quantum optical implementation is presented.},
  langid = {english},
  keywords = {Quantum Physics},
  file = {/Users/eric/Zotero/storage/MUQJI954/Giovannetti et al. - 2008 - Quantum random access memory.pdf}
}

@online{huangFasterQuantumAlgorithm2023,
  title = {A {{Faster Quantum Algorithm}} for {{Semidefinite Programming}} via {{Robust IPM Framework}}},
  author = {Huang, Baihe and Jiang, Shunhua and Song, Zhao and Tao, Runzhou and Zhang, Ruizhe},
  date = {2023-02-06},
  eprint = {2207.11154},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/2207.11154},
  urldate = {2024-05-03},
  abstract = {This paper studies a fundamental problem in convex optimization, which is to solve semidefinite programming (SDP) with high accuracy. This paper follows from existing robust SDP-based interior point method analysis due to [Huang, Jiang, Song, Tao and Zhang, FOCS 2022]. While, the previous work only provides an efficient implementation in the classical setting. This work provides a novel quantum implementation.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Quantum Physics},
  file = {/Users/eric/Zotero/storage/VYAH5RAX/Huang et al. - 2023 - A Faster Quantum Algorithm for Semidefinite Progra.pdf}
}

@online{huangSolvingSDPFaster2021,
  title = {Solving {{SDP Faster}}: {{A Robust IPM Framework}} and {{Efficient Implementation}}},
  shorttitle = {Solving {{SDP Faster}}},
  author = {Huang, Baihe and Jiang, Shunhua and Song, Zhao and Tao, Runzhou and Zhang, Ruizhe},
  date = {2021-11-18},
  eprint = {2101.08208},
  eprinttype = {arxiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2101.08208},
  urldate = {2024-05-03},
  abstract = {This paper introduces a new robust interior point method analysis for semidefinite programming (SDP). This new robust analysis can be combined with either logarithmic barrier or hybrid barrier.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Optimization and Control},
  file = {/Users/eric/Zotero/storage/GPJJCVJF/Huang et al. - 2021 - Solving SDP Faster A Robust IPM Framework and Eff.pdf}
}

@article{jordanFastQuantumAlgorithm2005,
  title = {Fast Quantum Algorithm for Numerical Gradient Estimation},
  author = {Jordan, Stephen P.},
  date = {2005-07-28},
  journaltitle = {Phys. Rev. Lett.},
  volume = {95},
  number = {5},
  eprint = {quant-ph/0405146},
  eprinttype = {arxiv},
  pages = {050501},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.95.050501},
  url = {http://arxiv.org/abs/quant-ph/0405146},
  urldate = {2024-05-03},
  abstract = {Given a blackbox for f, a smooth real scalar function of d real variables, one wants to estimate the gradient of f at a given point with n bits of precision. On a classical computer this requires a minimum of d+1 blackbox queries, whereas on a quantum computer it requires only one query regardless of d. The number of bits of precision to which f must be evaluated matches the classical requirement in the limit of large n.},
  langid = {english},
  keywords = {Quantum Physics},
  file = {/Users/eric/Zotero/storage/XJFK4WAL/0405146v2.pdf}
}

@article{leeSolvingLinearPrograms,
  title = {Solving {{Linear Programs}} with {{O}}( Rank) {{Linear System Solves}}},
  author = {Lee, Yin Tat and Sidford, Aaron},
  abstract = {We present an algorithm that given a linear program with n variables, m constraints, and constraint matrix A, computes an -approximate solution in O( rank(A) log(1/ )) iterations with high probability. Each iteration of our method consists of solving O(1) linear systems and additional nearly linear time computation, improving by a factor of Ω˜ ((m/ rank(A))1/2) over the previous fastest method with this iteration cost due to Renegar (1988) [51].1 Further, we provide a deterministic polynomial time computable O(rank(A))-self-concordant barrier function for the polytope, resolving an open question of Nesterov and Nemirovski (1994) [47] on the theory of “universal barriers” for interior point methods.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/eric/Zotero/storage/BTADTHWK/Lee and Sidford - Solving Linear Programs with O( rank) Linear Syste.pdf}
}

@article{mittalLecturePositiveSemidefinite,
  title = {Lecture 7: {{Positive Semideﬁnite Matrices}}},
  author = {Mittal, Rajat},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/eric/Zotero/storage/PWTV92BJ/Mittal - Lecture 7 Positive Semideﬁnite Matrices.pdf}
}

@article{muscoLecture17Interior,
  title = {Lecture 17: {{Interior Point Methods}}},
  author = {Musco, Christopher},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/eric/Zotero/storage/9IWCW6FT/Musco - Lecture 17 Interior Point Methods.pdf}
}

@online{tonksFastMatrixInversion2019,
  title = {On {{Fast Matrix Inversion}} via {{Fast Matrix Multiplication}}},
  author = {Tonks, Zak},
  date = {2019-01-03},
  eprint = {1901.00904},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1901.00904},
  urldate = {2024-05-04},
  abstract = {Volker Strassen first suggested an algorithm [Str69] to multiply matrices with worst case running time less than the conventional O(n3) operations in 1969. He also presented a recursive algorithm with which to invert matrices, and calculate determinants using matrix multiplication. James R. Bunch \& John E. Hopcroft improved upon this in 1974 [BH74] by providing modifications to the inversion algorithm in the case where principal submatrices were singular, amongst other improvements. We cover the case of multivariate polynomial matrix inversion, where it is noted that conventional methods that assume a field will experience major setbacks. Initially, there existed a presentation of a fraction free formulation of inversion via matrix multiplication along with motivations in [TDS17], however analysis of this presentation was rudimentary. We hence provide a discussion of the true complexities of this fraction free method arising from matrix multiplication, and arrive at its limitations.},
  langid = {english},
  pubstate = {preprint},
  keywords = {68W30,Computer Science - Symbolic Computation},
  file = {/Users/eric/Zotero/storage/8L45YNQ2/Tonks - 2019 - On Fast Matrix Inversion via Fast Matrix Multiplic.pdf}
}

@article{wierichsGeneralParametershiftRules2022,
  title = {General Parameter-Shift Rules for Quantum Gradients},
  author = {Wierichs, David and Izaac, Josh and Wang, Cody and Lin, Cedric Yen-Yu},
  date = {2022-03-30},
  journaltitle = {Quantum},
  volume = {6},
  eprint = {2107.12390},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  pages = {677},
  issn = {2521-327X},
  doi = {10.22331/q-2022-03-30-677},
  url = {http://arxiv.org/abs/2107.12390},
  urldate = {2024-05-03},
  abstract = {Variational quantum algorithms are ubiquitous in applications of noisy intermediate-scale quantum computers. Due to the structure of conventional parametrized quantum gates, the evaluated functions typically are finite Fourier series of the input parameters. In this work, we use this fact to derive new, general parameter-shift rules for single-parameter gates, and provide closed-form expressions to apply them. These rules are then extended to multi-parameter quantum gates by combining them with the stochastic parameter-shift rule. We perform a systematic analysis of quantum resource requirements for each rule, and show that a reduction in resources is possible for higher-order derivatives. Using the example of the quantum approximate optimization algorithm, we show that the generalized parameter-shift rule can reduce the number of circuit evaluations significantly when computing derivatives with respect to parameters that feed into many gates. Our approach additionally reproduces reconstructions of the evaluated function up to a chosen order, leading to known generalizations of the Rotosolve optimizer and new extensions of the quantum analytic descent optimization algorithm.},
  langid = {english},
  keywords = {Quantum Physics},
  file = {/Users/eric/Zotero/storage/G7W2HTQI/Wierichs et al. - 2022 - General parameter-shift rules for quantum gradient.pdf}
}

@article{wuInexactFeasibleQuantum2023,
  title = {An {{Inexact Feasible Quantum Interior Point Method}} for {{Linearly Constrained Quadratic Optimization}}},
  author = {Wu, Zeguan and Mohammadisiahroudi, Mohammadhossein and Augustino, Brandon and Yang, Xiu and Terlaky, Tamás},
  date = {2023-02-10},
  journaltitle = {Entropy},
  volume = {25},
  number = {2},
  pages = {330},
  issn = {1099-4300},
  doi = {10.3390/e25020330},
  url = {https://www.mdpi.com/1099-4300/25/2/330},
  urldate = {2024-05-05},
  abstract = {Quantum linear system algorithms (QLSAs) have the potential to speed up algorithms that rely on solving linear systems. Interior point methods (IPMs) yield a fundamental family of polynomial-time algorithms for solving optimization problems. IPMs solve a Newton linear system at each iteration to compute the search direction; thus, QLSAs can potentially speed up IPMs. Due to the noise in contemporary quantum computers, quantum-assisted IPMs (QIPMs) only admit an inexact solution to the Newton linear system. Typically, an inexact search direction leads to an infeasible solution, so, to overcome this, we propose an inexact-feasible QIPM (IF-QIPM) for solving linearly constrained quadratic optimization problems. We also apply the algorithm to 1-norm soft margin support vector machine (SVM) problems, and demonstrate that our algorithm enjoys a speedup in the dimension over existing approaches. This complexity bound is better than any existing classical or quantum algorithm that produces a classical solution.},
  langid = {english},
  file = {/Users/eric/Zotero/storage/IZ9NDZ7Y/Wu et al. - 2023 - An Inexact Feasible Quantum Interior Point Method .pdf}
}
