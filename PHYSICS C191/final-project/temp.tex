\documentclass[11pt]{article}
\usepackage{local}
\usepackage{forest}
\urlstyle{same}

\usepackage[style=numeric, sorting=none, maxnames=3]{biblatex}
\addbibresource{references.bib}


\newtheorem{theorem}{Theorem}
\newcommand{\classcode}{Physics C191}
\newcommand{\classname}{Quantum Speedups to Semidefinite Programming}

\renewcommand{\maketitle}{%
\hrule height4pt
Yutong Du, Jean-Luc Lupien \hfill \large{\classcode}
\newline
\large{Final Project} \Large{\hfill \classname \hfill} \large{\today}
\hrule height4pt \vskip .7em
\small{Header styling inspired by CS 70: \url{https://www.eecs70.org/}}
\normalsize
}

\linespread{1.1}
\begin{document}
	\maketitle
	\section{Introduction}
	Semidefinite programming (SDP), or more generally the problem of convex optimization, is a class of problems that has many practical applications, and is also incidentally one class of problems that classical computers are relatively weak at. In this report,  we first establish the framework of a semidefinite program, discuss the leading solution philosophies, then explore how research into quantum SDP solvers has produced significantly faster algorithms than their classical counterparts. The investigation into these algorithms continues to push the boundaries of quantum computing, and is another shining example of quantum advantage.

    \subsection{Contribution Statement}
    
    For this paper, the contribution is as follows: Yutong Du was responsible for the introduction and description of linear programs (sections \ref{LP}, \ref{SDP} and \ref{Classical Algorithms}). Yutong was also responsible for the QRAM section (section \ref{QRAM}) and the Main result section (sections \ref{Main Result}, \ref{Quantum Spectral Approximation}, \ref{Gradient Estimation}, \ref{matrix-vector} and \ref{combining}) of the quantum algorithms. Jean-Luc was responsible for the literature review and algorithm comparison which are reflected in sections \ref{Other Optimizations} and \ref{Other Gradient Estimations}. Jean-Luc also wrote the conclusion (section \ref{conclusion}). All other sections are representative of combined work.

	\subsection{Linear Programs}
    \label{LP}
	To begin, let's look at a simpler problem: linear programming. In linear programming (LP), the goal is to find 
	the optimal (either a maximum or minimum) value of a \textit{linear objective equation}, which is an equation
	of the form:
	\[
	c_1x_1 + c_2x_2 + c_3x_3 
	\] 
	For convenience, we also employ a matrix vector representation -- the above equation can also be written as 
	\( \mathbf c^{\top} \mathbf x \), where the vector \( \mathbf c = \begin{bmatrix} c_1 & c_2 & c_3 \end{bmatrix} \) 
	and \( \mathbf x = \begin{bmatrix} x_1 & x_2 & x_3 \end{bmatrix}  \). Along with this equation, we also place 
	any number of linear constraints on the variables \( x_1, x_2 \), and \( x_3 \). For instance, if we had 2 
	constraints:
	\begin{align*}
		a_{11}x_1 + a_{12}x_2 &\le b_1\\
		a_{21}x_1 + a_{22}x_2 &\le b_2\\
		x_1, x_2 &\ge 0
	\end{align*} 
	this can also be written using matrix-vector notation: \( \mathbf{Ax} \le \mathbf b \). Here, \( \mathbf A \) is
	the matrix that gives us the coefficients of the constraint equations, \( \mathbf x \) is the same vector as 
	before, and \( \mathbf b \) is the constraint value. Finally, we have a nonnegativity constraint on the 
	variables, which can be written as \( \mathbf x \ge 0 \). Putting this all together, the following is the 
	statement of linear programs: 
	\begin{align*}
		\min_x \quad &\mathbf c^{\top} \mathbf x\\
		\text{s.t.} \quad &	\mathbf{Ax} \le  \mathbf b, \quad \mathbf x \ge 0
	\end{align*}
	Note that here we've written the problem in terms of a minimization, 
 but it is always possible to convert a 
	maximization problem into this form. Another thing to note is that in this formulation, the set of 
	constraints \( \mathbf{Ax} \le \mathbf b \) defines a \textit{convex} region, also called the 
	feasible region, in which the optimal value is to be found -- this will be important later.

	\subsection{Semidefinite Programs}
    \label{SDP}
	Now we move to the main focus of this project: semidefinite programs (SDPs). Here, instead of dealing with 
	vectors as our variables, we now deal with positive semidefinite matrices. 
	These are matrices that are symmetric and also have real eigenvalues, or more formally 
	speaking, a matrix \( \mathbf M \) is positive semidefinite if and only if:
	\begin{enumerate}[label=\arabic*.]
		\item \( \mathbf M \) is symmetric
		\item For any vector \( \mathbf v \), we have \( \mathbf v^{\top}\mathbf M \mathbf v \ge 0 \). 
	\end{enumerate}
	\cite{mittalLecturePositiveSemidefinite}. With that in mind, the spirit of the problem is the exact same as an LP: we have an objective function to 
	maximize, subject to a set of \( d \) constraints: 
	\begin{align*}
		\min \quad &\Tr \left(\mathbf C^{\top}\mathbf X\right)\\
		\text{s.t.}\quad & \Tr \left(\mathbf A_i^{\top}\mathbf X\right) \le  b_i \quad \text{for \( i = 1, 2, \dots, d \)}\\
						 & \mathbf X \succeq 0
	\end{align*}
	Here, \( \mathbf{C}, \mathbf X \) and \( \mathbf A_i \) are all positive semidefinite matrices instead of simple 
	vectors. Note that this is a more general class of problem than an LP; if \( \mathbf C \) and \( \mathbf X \) are 
	diagonal, then this problem reduces immediately to an LP. 

	While LPs and SDPs share thematic similarities, the generalization of moving from vectors to semidefinite matrices
	introduces some key differences \cite{freundIntroductionSemidefiniteProgramming}:
	\begin{enumerate}[label=\arabic*.]
		\item Properties concerning duality are lost. For LPs the concept of duality states that for every 
			LP, also called the \textit{primal} LP, 
			we can construct another ``equivalent'' LP called the \textit{dual} LP. Moreover, the strong 
			duality theorem states that if the primal LP has an optimal value, then the dual LP also has an optimal 
			value, and the optimal value for the dual is equal to that of the primal.   

			With SDPs, strong duality fails. The duality gap, defined to be the difference between the optimal 
			primal and dual problems, can be finite or even infinite. However, if both problems contain solutions in 
			the semidefinite cone, then the primal and dual share the same optimal value.  
		\item There are no known finite algorithms for solving SDPs. As we'll see, all of the solution methods 
			always approximate the solution, to some tolerance of \( \epsilon \).        
	\end{enumerate}
	Despite these differences, however, SDPs are not that much harder to solve than LPs, and in fact many LP 
	algorithms have been generalized to also work for SDPs as well.  

	\section{Classical Algorithms}
 \label{Classical Algorithms}
	Before diving into the quantum algorithms for this problem, it is useful to first take a look at the leading 
	philosophy developed to solve this problem classically. In particular, Interior Point Methods (IPM) are a incredible tool for solving SDPs (and therefore LPs). First introduced by Nesterov and Nemirovsky \cite{nesterov1994interior}, these methods are widely used in mathematical and engineering contexts and have great practical performance. 

	\subsection{Interior Point Methods}
    \label{IPM}
	In an Interior Point Method, the SDP 
	is rephrased as a functional problem: the objective function is denoted \( f_{\eta}(x) \), defined as:
	\begin{equation}\label{IPMprob}
	\min f_{\eta}(x) \quad \text{where}\quad f_{\eta}(x) = \eta c^{\top }x + f(x)
	\end{equation}
	In this formulation, the original objective function \( \mathbf c^{\top}\mathbf x \) corresponds to the first 
	term, and \( f(x) \) is a function known as a \textit{barrier function}. Without defining them explicitly, 
	one way to conceptually interpret \( f(x) \) is that it's a function that tends toward infinity as we 
	approach the barrier of the feasible region. In other words, \( f(x) \) is the function that encodes 
	the information about the constraints, i.e. \( \mathbf A_i^{\top} \mathbf X \) for SDPs. 
	There are multiple ways this barrier can be implemented, and as it 
	turns out, different ways of writing \( f(x) \) gives rise to drastically different runtime bounds.  
	
	The parameter \( \eta \) controls the contribution of the \( c^{\top}x \) term in \( f_{\eta}(x) \). When
	\( \eta \) is small, the constraints dominate, and the objective function dominates when \( \eta \) is large. In an IPM, we initialize $\eta=0$ and compute an approximate solution to equation \eqref{IPMprob} using iterative Newton steps. The value of $\eta$ is then increased and another Newton step is performed. These two steps are repeated until $\eta$ becomes sufficiently large to approximate the solution to the problem within a tolerance $\epsilon$.
	The point $x_{n+1}$ obtained after $n+1$ iterations is given by:
	\( x_{n+1} = x_n + n(x) \), where \( n(x) \), the Newton step, is defined as:
	\begin{equation}
	n(x) = -H(x)^{-1}g(x).
	\end{equation}
	Here, \( H(x) \) and \( g(x) \) are the Hessian matrix and gradient vectors respectively.
    Below we've included a diagram showing the path the IPM method takes from 
	\( x_0 \) to \( x_T \) in \( T \) steps (this diagram is inspired by \cite{muscoLecture17Interior}):
	\begin{center}
		\begin{tikzpicture}[scale=1.5]
			\draw[fill=gray!30] (0, 0) -- (2, 0.4) -- (2.5, 3) -- (0.4, 4) node[above] {\( x^{*} \) }-- (-1, 3.5) -- (-2, 1.5) -- cycle;
			\draw node at (0.5, 2) {\( K \) };
			\draw [green!50!black, -stealth] plot [smooth] coordinates {(-1.3, 1.8) (-0.7, 2.8) (0.2,3) (0.4, 3.7)}
				node[right] { \( x_T \) };
            \draw[red!50!black, -stealth] (3.5, 3) -- (3.5, 4) node[above] {\( -\mathbf c \)};
		\end{tikzpicture}
	\end{center}

	In theory, our point \( x_n \) equals \( x^{*} \) when \( \eta \to \infty \) and \( T \to \infty \). 
	As this is not possible 
	in a finite process, the best we can hope to do is to get approximately close to \( x^{*} \), which echoes 
	what we mentioned earlier about the lack of a finite algorithm for solving SDPs. 

 However, we can leverage the inherent properties of SDPs and LPs to bound the number of iterations needed given a desired precision $\epsilon\in\mathbb{R}$. It is proven in \cite{boydConvexOptimization2004} that the number of Newton step iterations is $O(\log \frac{1}{\epsilon})$. Notably, this bound holds for both classical and quantum methods. Therefore, speedup is achieved by reducing the time taken to perform each Newton step not in reducing the total number of iterations.

	%As this is an iterative method, the runtime of this algorithm is heavily dependent on the number of iterations
	%\( T \) we choose to run, and here we come to the main issue for IPM algorithms: 
     Each Newton step is an 
	incredibly costly computation, since it requires calculating a matrix inverse and a matrix multiplication. 
	Classically, the fastest known matrix multiplication algorithm runs in \( O(n^{2.37}) \)
	\footnote{This algorithm 
		is also considered a ``galactic algorithm'', or in other words, extremely impractical, and in practice 
		the slower (but much easier) Strassen's algorithm is used instead, which has a runtime of roughly 
	\( O(n^{2.8}) \).}, and the fastest matrix inverse algorithms run close to \( O(n^3) \), both of which are 
	incredibly slow.  

	With this in mind, there are several approaches we can take to easing the computational burden here. Perhaps 
	the most obvious way is to find a faster way to perform matrix multiplication and inversion, which is a valid 
	approach, however it's hard to imagine that this will generate appreciable speedup as it does nothing to affect 
	the number of iterations we have to compute. On the other hand, 
	a more promising approach, and one that we will focus on 
	in subsequent sections, lies in finding ways to shrink the matrices \( H \) and \( g \) to make them more 
	tractable, by way of approximations. This lessens the computational burden in two ways: first, a smaller \( H \)
	and \( g \) means calculating \( H^{-1} \) and multiplying it with \( g \) is faster, and second, 
	approximations reduce the number of times we need to compute Newton's step. 


In sum, there are three main steps that incur a high computational cost when using an IPM which are the following:

\begin{enumerate}
\item Calculating and storing the Hessian matrix $H(x)$ and the gradient $g(x)$
    \item Calculating the inverse of the Hessian matrix $H(x)^{-1}$.
    \item Calculating the matrix-vector product $H(x)^{-1}g(x)$.
\end{enumerate}

If we consider a constant tolerance $\epsilon$, the best classical runtime achieved is somewhere on the order of \( \widetilde
O(nd + d^{3})\). As we'll see, the quantum algorithm we focus on has an optimal runtime of \( \widetilde O(
\sqrt{n} \ \mathrm{poly}(d))\), which is much faster. 

\section{Quantum Random Access Memory}
\label{QRAM}
	A crucial subroutine in many quantum solvers is the quantum implementation of classical 
	random access memory, also called QRAM. We will now discuss this subroutine and its importance to quantum solvers. In essence, QRAM provides an \( O(n) \to O(\log n) \) speedup in 
	query length, and is one of the major subroutines used to achieve a better runtime. 

	The philosophy behind QRAM is relatively simple: instead of accessing a single memory location, 
	QRAM uses superposition to access multiple memory locations at once. This can be implemented in different ways, 
	one of which is the ``bucket-brigade'' implementation described in \cite{giovannettiQuantumRandomAccess2008}. To explain how this works, consider a classical 
	RAM with \( n \) bits, which encodes for \( 2^{n} \) memory locations. Now, since there are \( 2^{n} \) locations, 
	we can imagine each memory location being a leaf in a full binary tree with \( n \) layers:  

	\begin{center}
		\begin{forest}
			[\( \cdot \) [\( 0 \) [\( 0 \) [ \( X_{00} \)]] [\( 1 \) [\( X_{01} \) ]]] [\( 1 \) 
			[ \( 0 \) [\( X_{10} \) ]] [\( 1 \) [ \( X_{11} \) ]]]]
		\end{forest}
	\end{center}
	Then, the data at location \( X_{ab} \) can be specified by the binary string \( ab \), where the value of 
	\( a \) and \( b \) trace the path from the root node to the leaf in question. Note that the path 
	is traced from most to least significant bit -- for instance, \( X_{01} \) 
	is encoded by the bits \( a = 0, b = 1 \). 

	Quantumly, the idea is more or less the same, except now, each node is replaced by a three-state system, 
	sometimes called a qutrit. The states are \( \ket*{\cdot}, \ket*{0} \) and \( \ket*{1} \). The \( \ket*{\cdot} \) 
	state is referred to as a ``wait'' has the special property that whenever a state, either \( \ket*{0} \) 
	or \( \ket*{1} \) is received, the state transforms into the received state. That is, if it receives \( \ket*{0} \),
	then \( \ket*{\cdot} \to \ket*{0} \), and the same goes for \( \ket*{1} \). Then, to access a particular 
	cell, we specify the path to that cell by feeding in the path one qubit at a time, 
	just like we did classically; the diagram below shows an example 
	where we try to access \( \ket*{X_{01}} \):

	\begin{center}
		\begin{forest}
			[\( \cdot \) [\textcolor{red}{\( \ket*{0} \)} [\( \ket*{\cdot} \) [ \( \ket*{X_{00}} \)]] 
			[\textcolor{red}{\( \ket*{1} \)} 
			[\textcolor{red}{\( \ket*{X_{01}} \) }]]] [\( \ket*{\cdot} \) 
			[ \( \ket*{\cdot} \) [\( \ket*{X_{10}} \) ]] [\( \ket*{\cdot} \) [ \( \ket*{X_{11}} \) ]]]]
		\end{forest}
	\end{center}
	the red markers indicates the path taken to \( \ket*{X_{01}} \). Now, how is this faster than the classical 
	approach? Well, the key comes when we consider superpositions of states. What if, instead of feeding in  
	just \( \ket*{0} \) or \( \ket*{1} \), we instead fed \( \ket*{+} = \frac{1}{\sqrt{2} }(\ket*{0} + \ket*{1}) \) 
	twice? Well, then both paths would be activated due to superposition, and as a result instead of getting a single 
	qubit as earlier, we would get a superposition of all four memory states: 
	\[
	\frac{1}{2}(\ket*{X_{00}} + \ket*{X_{01}} + \ket*{X_{10}} + \ket*{X_{11}})
	\] 
	In general, for a QRAM of \( n \) qubits, if we gave \( \ket*{+}^{\otimes n} \) as an input (in succession), 
	then the output 
	would just be a superposition of all the memory states. This is the power of QRAM -- with  
	only \( n \) queries, we managed to access \( 2^{n} \) different memory locations, or equivalently, for \( n \) 
	memory locations we only need \( \log n \) queries. This is why QRAM introduces an \( O(n) \to 
	O(\log n)\) speedup.   

	As we'll see, QRAM is one of the central subroutines that are assumed to be implemented in the algorithm we 
	will focus on. This is also true for many other quantum algorithms out there -- they assume access to 
	QRAM, and as a result they are able to claim a \( O(n) \to O(\log n) \) query time basically for free.  


\section{Quantum IPM Algorithms} 
 
	Now that we are familiar with optimization problems and challenges in implementing an efficient algorithm classically, 
	we move to investigating how quantum algorithms can be used to generate speedups. In 
	particular, we will focus on the paper by Apers and Gribling \cite{apersQuantumSpeedupsLinear2024}, who propose a new quantum IPM algorithm that 
	bypasses many of the challenges encountered by the algorithms that precede it. 

 
 Before we begin discussing the algorithm, it is useful to first take a look at some other algorithms from the literature that attempt to speedup convex optimization.


 \subsection{Optimization Approaches from the Litarature}
 \label{Other Optimizations}
 Because of the inherent efficiency in terms of Newton iterations obtained by IPMs, most algorithms use the same general architecture as classical IPMs. A few such techniques are listed here.
 A seminal work in this space was presented by Brandao in \cite{brandaoQuantumSDPSolvers2019} which leverages a quantum matrix multiplicative weight approach to achieve speedups for solving SDPs. Specifically, supposing quantum access to the matrices encoding the SDP, this algorithm achieves  \( \widetilde
O(\sqrt{d}\cdot \text{poly}(\log d, \log n, r, 1/\epsilon)\), where $r$ denotes the maximum rank of input matrices and $\epsilon$ is the required precision. An improvement to this algorithm is presented in \cite{wuInexactFeasibleQuantum2023} which uses an approximate quantum linear solver to identify inexact search directions. This paper addresses the largest issue associated with inexact search techniques which is the possibility of obtaining infeasible solutions.  Recently,  a quantum implementation of the fast SDP solver \cite{huangFasterQuantumAlgorithm2023} was presented in \cite{huangSolvingSDPFaster2021} which exhibits very fast $O(d^{1.5}n^2 \log(1/\epsilon)$ time complexity. This complexity is achieved under very strict assumptions however and notably depends on a condition-number. 

A different approach to optimization of LPs is presented in \cite{augustinoQuantumCentralPath2023} which encodes the central path of an IPM into a Hamiltonian. The evolution of  this Hamiltonian is then performed using quantum Schrodinger simulation which will converge with high probability to the optimal solution of the LP. This technique presents two distinguishing features: it does not depend on a bounded condition number of the input matrices and it does not require multiple iterations to reach the desired solution. However, this comes at the expense of a high number of required quantum gates. Indeed, the number of quantum gates required is $O((n+d)\text{nnz}(A)\log(n)\text{polylog}(d, n))$, where $\text{nnz}(A)$ denotes the number of non-zero elements of $A$. This makes actual use of this algorithm extremely impractical given the current difficulties with creating large-scale quantum circuits.





 
 
\subsection{Main Result}
\label{Main Result}
One of the main obstacles in obtaining a good quantum SDP solver is the assumption of a bounded condition-number. This is highlighted by approaches presented in \cite{brandaoQuantumSDPSolvers2019, wuInexactFeasibleQuantum2023, huangFasterQuantumAlgorithm2023} which are all dependent on a bounded condition-number. In essence, 
a condition number bound implies that the runtime of the algorithm was highly dependent on the 
values to the input matrices; this is problematic because it means that the runtime of such algorithms 
varies wildly depending on the values to the input matrix. However, this algorithm we will focus on removes 
that dependence entirely, and as such is seen as a monumental achievement in the search for a faster 
quantum IPM algorithm. 

In particular, this algorithm develops two main subroutines \cite{apersQuantumSpeedupsLinear2024}:
\begin{enumerate}[label=\alph*)]
	\item An efficient algorithm to spectrally approximate the Hessian. 
	\item An efficient algorithm to approximate a matrix-vector product. 
\end{enumerate}
The implementation of these algorithms allow us to calculate an approximate Hessian \( Q(x) \) and gradient 
\( \tilde g(x) \), which is then used to approximate the update step via \( \tilde n(x) = -Q(x)^{-1} \tilde g(x) \).
To be a bit more specific, it turns out that in this particular case \( \tilde g(x) \) can be calculated directly 
from \( Q(x) \), which is why we don't need an efficient algorithm to calculate \( \tilde g(x) \) alone. 

\subsection{Quantum Spectral Approximation}
\label{Quantum Spectral Approximation}
As this is one of the main subroutines the paper leverages, it is one that is important to look at if one is to 
understand the entire algorithm. As outlined in Theorem 3.1 of \cite{apersQuantumSpeedupsLinear2024}, 
the following is the formal statement of the spectral 
approximation:

\begin{theorem}[Quantum Spectral Approximation]
	Consider query access to a matrix \( B \in \R^{n \times d} \) with row sparsity \( r \). For any \( 0 < 
	\epsilon \le 1\), there is a quantum algorithm that, with high probability, returns a matrix \( \tilde B^{
	\widetilde O(d / \epsilon^2) \times d} \) satisfying 
	\[
		(1 - \epsilon) \tilde B^{\top} \tilde B \preceq B ^{\top} B \preceq (1 + \epsilon) \tilde B^{\top} \tilde B
	\] 
	while making \( \widetilde O(\sqrt{nd}  / \epsilon) \) row queries to \( B \), and taking time 
	\( \widetilde O(r\sqrt{nd} / \epsilon + d^{\omega}) \).  
\end{theorem}
Intuitively, this theorem is best understood as the following: given a matrix \( B \) in \( \R^{n \times d} \), 
we can use this algorithm to find a matrix \( \tilde B \) such that \( \tilde B^{\top} \tilde B \) is 
within \( \epsilon \) of the true value of \( B^{\top} B \).\footnote{More accurately, we should say that 
	if \( A \preceq B \) then this is the same as \( 0 \preceq B - A \), or in other words the matrix \( B - A \) is 
positive semidefinite. However, the analogy of ``values'' suffices for a conceptual understanding.}  

The reason this spectral approximation is phrased in this way is in part due to the form of the Hessian matrix 
for \( f(x) \). In summary, because all the Hessian matrices considered in the paper are of the form 
\( B^{\top}B \), then the above algorithm perfectly allows us to approximate \( H \).  

The method in which this is done is actually quite complicated -- the authors make use of an algorithm called 
the \textit{repeated halving algorithm} developed in \cite{cohenEll_pRowSampling2014}. 
In essence, the algorithm works in two parts: first, 
a set of matrices \( A_1, \dots, A_{L} \) is recursively constructed by subsampling \( A \); in other words, 
to generate \( A_{i + 1} \), we keep each row in \( A_i \) with probability \( \frac{1}{2} \). This is then 
combined another subsampling procedure that allows us to construct a matrix \( B_i \) from each \( A_i \). In 
the paper, this is denoted as the step \( B \overset{w, \epsilon}{\leftarrow} A \). Here, instead of each row 
being kept with uniform probability, there is a distribution \( p_i \) instead, which is dependent on the 
dimension of \( A \) along with other factors. This process is recursively done, and once all the 
computation is done we are left with a matrix \( B \) which approximates \( A \) in the sense 
that \( B^{\top}B \approx_\epsilon A^{\top}A \). This notation effectively means that 
\( B^{\top} B \) is approximately equal to \( A^{\top} A \), to a tolerance of 
\( \epsilon \). 

Quantumly, this latter process of \( B \overset{w, \epsilon}{\leftarrow} A \) is interesting, because its quantum 
implementation is actually rather simple. In particular, this step is actually implemented via Grover search 
\cite{apersQuantumSpeedupGraph2023}, which 
is used to select the rows in \( A \) that we want to use to construct \( B \). It should also be noted that 
this step in particular is one that benefits greatly from QRAM access, since accessing multiple rows of \( A \), which 
is necessary to construct \( B \) would be made far more efficient with QRAM as we can access all these rows 
at once.  
 
This result is then used in conjunction with calculations of leverage scores and Lewis weights in order to 
fully compute an approximation to \( H(x) \). However, the process by which the Lewis weights 
are calculated are relatively complicated, and we will not analyze them in detail in this report. However, 
we will point to \cite{apersQuantumSpeedupsLinear2024} for further reading.  


\subsection{Gradient Estimation} 
\label{Gradient Estimation}
Perhaps the more interesting of the two subroutines introduced is this efficient method of calculating the matrix-vector product used to define the gradient. In particular, the algorithm presented in 
the paper of focus \cite{apersQuantumSpeedupsLinear2024} uses a quantum matrix-vector approximation algorithm to estimate the gradient of the barrier function. Before we 
delve into the specifics of this algorithm, it is useful to look historically at what's 
been done already.

\subsubsection{Other Gradient Estimation Algorithms}
\label{Other Gradient Estimations}
Gradient estimation has been an area of major research for quantum algorithms and is pivotal for most quantum SDP solvers. 
One of the first such algorithms is Jordan's algorithm \cite{jordanFastQuantumAlgorithm2005} which supposes black-box access to a function 
and can compute the gradient of said function in constant time. 
This algorithm is of little practical use for SDP solvers, 
however, as we have analytical access to the functions in question. Another approach that does make use of analytical information is a parameter shift technique for calculating gradients of quantum functions. Given a function encoded in a quantum circuit, parameter-shift rules are employed to calculate the gradients from the same circuit architecture as that of the original quantum function. This result is presented in \cite{wierichsGeneralParametershiftRules2022}. This technique is difficult to apply to general optimization problems, however, as the barrier function would have to be encoded within quantum circuits prior to running the optimization. This incurs a higher time cost rather than just storing and accessing the constraint matrices through QRAM.

Gradients can also be estimated though shadow tomography as seen in \cite{abbasQuantumBackpropagationInformation2023}. However, this process requires many copies of an initial quantum state which would render the process too complex for use in optimization.

\subsubsection{Quantum Matrix-Vector Approximation} 
\label{matrix-vector}

Now we turn to the algorithm outlined in \cite{apersQuantumSpeedupsLinear2024}. As mentioned, it is effectively 
a gradient estimation algorithm that uses previous quantum matrix-vector approximation algorithms, and is outlined in Theorem 5.1 of \cite{apersQuantumSpeedupsLinear2024}:

\begin{theorem}[Approximate matrix-vector product]
	Assume query access to a vector \( v \in \R^{n} \) and a matrix \( B \in \R^{n \times d} \) with 
	row sparsity \( r \). There is a quantum algorithm that returns a vector \( \tilde y \) satisfying 
	\[
		\|\tilde y - B^{\top} v\|_{(B^{\top} B)^{-1}} \le  \delta
	\] 
	while making \( \widetilde O(\sqrt{n} d \|v\|_{\infty} / \delta) \) row queries to \( B \) and \( v \), and 
	taking time \( \widetilde O(r \sqrt{n} d^2 \|v\|_{\infty} + d^{\omega}) \).
\end{theorem}
In other words, this algorithm takes in an input \( B\in \R^{n \times d} \)	and \( v \in \R^{n} \), and 
finds a vector \( \tilde y \) that gets arbitrarily close (because we 
choose the value of \( \delta \)) to the value of \( B^{\top} v \), which is the matrix vector product. In the 
context of our IPM algorithm, this is the algorithm that finds an approximation to the quantity equivalent 
to the quantity \( Q(x)^{-1}\tilde g(x) \). 

Similar to the spectral approximation, the implementation of this algorithm is also rather complex, and uses 
other algorithms such as the quantum multivariate mean estimation from 
\cite{cornelissenNearOptimalQuantumAlgorithms2022} to arrive at a result. Despite this, the main points 
are relatively easy to understand. First, the input matrix \( B \) is spectrally approximated as \( \tilde W \) 
using the spectral approximation we talked about earlier as a subroutine. This outputs \( \tilde W \), which we then 
convert to \( \tilde W^{ - 1 / 2} \) classically. Now, this quantity is used in conjunction with \( v \) to 
generate a random variable \( X \) from which the quantum multivariate mean subroutine is used, ultimately 
returning a vector \( \tilde \mu \). Then, we return \( W^{ 1 / 2} \tilde \mu = \tilde y\) as the approximation. 

While the details as to \textit{why} the algorithm works is rather technical, the important point is the following: 
the quantum multivaraite mean algorithm is incredibly efficient, and the authors get around having to 
explicitly approximation \( B^{\top} v \) by using this algorithm to output an estimate \( \tilde \mu \) which 
we use to output \( \tilde y \). 
 

\subsection{Putting it all Together}
\label{combining}
Now, we are ready to put everything together. Recall in section \ref{IPM}, we discussed that depending on the way 
we encode our barrier function \( f(x) \), the resulting time (and space) complexity of the quantum algorithm is 
different. In \cite{apersQuantumSpeedupsLinear2024}, the authors detail the implementation of their quantum 
algorithm for three different barriers, of which we will focus on the fastest one: the Lewis weight barrier. 
   
The idea of a Lewis weight barrier is inspired by \cite{leeSolvingLinearPrograms}, which defines \( f(x) \) 
as follows:
\[
f(x) = \ln \det(A^{\top}S_x^{-1} W_x^{1 - \frac{2}{p}}S_x^{-1}A) \quad \text{where}\quad 
W_x = \mathrm{Diag}(w^{(p)}(S_x^{-1}A))
\] 
Where \( A \) is the input matrix, and \( S_x \) is a matrix calculated based on the Lewis weights, which as 
mentioned, is a process that we do not fully understand, and will not discuss in detail here. The reason 
this approach is used is because the gradient and Hessian matrices take on a relatively nice form:
\[
	g(x) = -A^{\top} S_x^{-1} W_x \mathbf{1} \quad H(x) = A^{\top} S_x^{-1}W_x S_x ^{-1} A
\] 
Then, leveraging the forms of these matrices, we can apply the spectral and the matrix-vector 
approximation algorithms here to approximate these quantities. This is also done in a very clever way: for \( H \), 
instead of spectrally approximating \( H \), we spectrally approximate the quantity \(B = W_x^{1 / 2}S_x^{-1} A \)
outputting a matrix \( \tilde B \), with the guarantee that \( \tilde B^{\top} \tilde B \approx H(x) \). A similar 
approach is done to approximate \( g(x) \), where we allow \( B = W_x^{1 / 2}S_x^{-1}A \) and 
\( v = W_x^{1 / 2} \mathbf 1 \), whose product is equal to \( g(x) \). 

This last step highlights the major contribution of this paper: the authors were able to find a way to separate 
\( H(x) \) and \( g(x) \) in an incredibly clever way, such that we can apply these algorithms like the 
spectral and matrix-vector approximation in order to approximate \( H \) and \( g \) with an extremely fast 
runtime. In addition to these algorithms, all of these algorithms benefit from QRAM, as they all (at some point in their execution) demand query access to objects multiple times, which is made significantly more efficient with the implementation of QRAM. Then, combining all these algorithms and structures together, we finally arrive at a runtime of 
\[
	\widetilde O(\sqrt{n} \ \mathrm{poly}(d, \log(n), 1 / \epsilon))  
\] 
which is incredibly fast. Notably, the dependence on $O(\sqrt(n))$ rather than $O(n)$ in the classical setting, is the most striking improvement in complexity. This quantum runtime is considered significantly faster than the \( O(nd + d^3) \) classical runtime due to the polylog depedence in parameters $d$ and $n$.

However, because this implementation depends on many sampling steps for each iteration of the IPM method, the constant multiplicative factor in front of this complexity result is non-negligible. This makes this algorithm impractical for small calculations where classical methods would have a much faster actual runtime. Furthermore, current quantum computing frameworks do not allow for large-scale implementations which means that it impossible to solve large SDPs with this method. This greatly limits the current applicability of such methods to real-world problems. The hope is to eventually be able to implement large-scale quantum circuits which will be able to solve large SDPs impossible to do classically.

 

\section{Conclusion and Future Directions}
\label{conclusion}
Overall, this exploration highlights the speedup that can be gained from utilizing quantum algorithms to solve SDPs compared to their classical counterparts. Although the inherent structure of the IPM algorithm is very efficient, quantum algorithms can greatly speedup matrix estimation, linear system solving, and matrix accessing steps integral to the Newton step. Utilizing such quantum algorithms therefore enables considerable speedup when used in conjuction with classical frameworks. 

Despite these speedups, there is still much more room for this field to advance. For instance, perhaps the most obvious area of improvement, is to find an experimental way to implement such an algorithm. It is well known that many quantum algorithms, for instance Shor's algorithm, are theoretically faster than classical algorithms, but remain non-functional to this day because we have not yet figured out how to build a fault-tolerant way to implement these algorithms. 

This same principle is also what hinders these SDP algorithms. Specifically, as mentioned, many of these algorithms leverage 
QRAM in order to demonstrate an enormous speedup, and this algorithm we investigated is no different. However, as far as we know, there are no known fault-tolerant ways of implementing QRAM, and as a result such algorithms remain only theoretically possible \cite{abbasQuantumOptimizationPotential2023}. 



There is also further direction on how to improve this particular algorithm outlined in \cite{apersQuantumSpeedupsLinear2024}. They suggest that because their gradient approximation runs in \( \widetilde O(\sqrt{n} d) \) whereas the theoretically 
optimal bound is \( \widetilde O(\sqrt{nd}) \), there is potential for improvement in this area. However, they haven't been extremely specific on how this may be accomplished, and instead just suppose that alternate, more efficient algorithms are possible. 

Finally, classical IPMs have a $\log(1/\epsilon)$ dependence, meaning they can achieve very high precision very quickly. The quantum algorithm of Apers (\cite{apersQuantumSpeedupsLinear2024}), however, has a $1/\epsilon$ dependence meaning precision is only reached linearly. This dependency problem has been addressed for specific instances such as in \cite{huangFasterQuantumAlgorithm2023} where $\log(1/\epsilon)$ dependence is achieved under strict assumptions and a condition-number bound. The next frontier in this space would be to simultaneously achieve good dependence in $1/\epsilon$, $n$ and $d$ without requiring a condition-number bound.

Regardless though, it will be incredibly interesting tracking the advancements in this field over the next several years.


%\bibliographystyle{ieee}
%\bibliography{ref}
\pagebreak
\nocite{*}
\printbibliography
% add appendix about other interesting subroutines
\end{document}
