\section{MST Continued, Set Cover}
	
	\subsection{Prim's Algorithm}
	\begin{itemize}
		\item The idea is to draw a tree by greedily adding the cheapest edge that can grow the tree.
		\item Start from some vertex, and repeatedly pick the lightest edge $(u, v)$ such that 
			$u \in S$ and $v \in V \setminus S$. 

			\question{How exactly is this different from Kruskal's algorithm? Aren't both using cuts in 
			the same way?}

			\answer{Kruskal's doesn't start from a given vertex, but instead just selects edges. Prim's 
			starts with vertices and looks at edges that connect from $S$ to $V \setminus S$}
		\item Remember: the shape of the MST is dependent on the node that we start at, but an MST will 
			always exist no matter which vertex we start at.  
		\item Both Prim's and Kruskal's algorithm works on negative edge weights. This is because the cut 
			property still holds, and the notion \textit{minimum} spanning tree is not broken with 
			negative edge weights.
	\end{itemize}

	\subsection{Implementation}
	\begin{itemize}
		\item The naive implementation of Prim's is actually quite slow, since on every added vertex we 
			are looking for new cuts and checking edges every time.
		\item We can optimize by using priority queues (basically a max heap based on priority).  

			\question{Is this true about priority queues?}
		\item So here are the things we need to keep track of:
			\begin{itemize}
				\item For every edge $v \in V \setminus S$, check whether $v$ has a direct 
					edge of the set $S$ of ``visited'' vertices, and also the cost of the lightest 
					edge connecting
					$v$ to the set $S$ of visited vertices.
				\item We had the same dilemma before, with Dijkstra's algorithm!
			\end{itemize}
		\item So let's follow the same procedure as Dijkstra's!
			\begin{itemize}
				\item First start with $\dist(v)$ set to infinity, and $\prev(v)$ to null for 
					every vertex.
				\item If a neighbor $u$ is added to $S$ (visited set) and $\dist(v) > w_{u, v}$, then 
					we update $\dist(v) = w_{(u, v)}$, and set $\prev(v) = u$. 
				\item This is slightly different from Dijkstra's, where the dist array instead marks 
					the minimum edge between two visited nodes, instead of the total distance 
					from a certain vertex. 
				\item Part of the reason for this is that MSTs don't care about where you start. 
			\end{itemize}
		\item The ``cut" in this case is actually the process of adding adjacent edges from visited nodes
			to unvisited ones into the priority queue. 
	\end{itemize}
	\subsection{Runtime}
	\begin{itemize}
		\item For a priority queue: we can either use a binary heap ($O(\log n)$ for each operation) or 
			fibonacci heap (a little bit better, since $\log(n)$ for inserts but $O(1)$ for everything else. 
		\item So because of the constant time for Fibonacci heap, it has $O(m + n \log n)$ time, whereas
			a binary heap has $O((m + n) \log n)$.
		\item Comparing both algorithms:
			\begin{itemize}
				\item Kruskal's: $O((m + n) \log n)$
				\item Prim's (with Fibonacci heap) $O(m + n \log n)$.
				\item For sparse graphs (so ones with not many edges), both are equally as good.
				\item For dense graphs, Prim's is much better. 
			\end{itemize}
	\end{itemize}
	\subsection{Set Cover Problem}
	\begin{itemize}
		\item Input: the universe of $n$ elements $U = \{1, \dots, n\}$, and subsets 
			$S_1, S_2, \dots, S_m \subseteq U$, such that $\bigcup_{i = 1}^m S_i = U$. 
		\item Output: A collection of $S_i$ of minimal size.
		\item This is an example of a problem where the greedy algorithm is \textit{not optimal!} Instead, 
			it is approximately optimal. 
		\item Claim: if the optimal solution uses $k$ sets, then the greedy algorithm uses 
			at most $k \ln n$ sets. 
		\item We will prove this recursively: let $n_t$ be the number of elements not covered by the greedy 
			algorithm after $t$ choices. Then, we can reframe the problem to be that 
			when $t = k \ln n$, we want $n_t < 1$. 
			\begin{itemize}
				\item Subclaim 1: $n_1 \le n_0 - \frac{n_0}{k}$. 

					\textit{Proof:} the optimal solution requires $k$ sets to cover $U$, so the 
					average number of elements in any set is $\frac{n}{k}$. Hence, there is a set 
					that counts more than $\frac{n}{k}$ elements (if not equal).
				\item Subclaim 2: for any $t$, $n_{t+1} \le n_t(1 - 1 / k)$.
					
					\textit{Proof:} This is a natural extension of claim 1.  
			\end{itemize}
		\item With this proven, we introduce an \textbf{approximation factor}, which is a way to say that Greedy
			is optimal, with an approximation factor of $\ln n$. 
	\end{itemize}
