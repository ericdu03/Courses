\documentclass[11pt]{article}
\usepackage{header}
\def\title{HW 09}

\begin{document}
\maketitle
\fontsize{12}{15}\selectfont

\begin{center}
    Due: Saturday, 10/29, 4:00 PM \\
    Grace period until Saturday, 10/29, 6:00 PM \\
\end{center}

\section*{Sundry}
Before you start writing your final homework submission, state briefly how you worked on it.  Who else did you work with?  List names and email addresses.  (In case of homework party, you can just describe the group.)

{\color{blue}{I went to office hours on thursday and friday to receive guidance on problems 3 and 6, and I worked on problem 2 with a couple people there who stayed after office hours were over on thursday.}}

\vspace{15pt}

\Question{Cliques in Random Graphs}

Consider the graph $G = (V,E)$ on $n$ vertices which is generated by the following random process: for each pair of vertices $u$ and $v$, we flip a fair coin and place an (undirected) edge between $u$ and $v$ if and only if the coin comes up heads.

\begin{Parts}
\Part What is the size of the sample space?

\begin{solution}
    There are ${n \choose 2}$ edges in our graph, and each edge is either colored or not colored. Therefore, our sample space is going to be $2^{n \choose 2}$.
\end{solution}

\Part A $k$-clique in a graph is a set $S$ of $k$ vertices which are pairwise adjacent (every pair of vertices is connected by an edge). For example, a $3$-clique is a triangle. Let $E_S$ be the event that a set $S$ forms a clique. What is the probability of $E_S$ for a particular set $S$ of $k$ vertices? 

\begin{solution}
    Here, we can choose our sample space to be the set of graphs with $k$ vertices. The size of this sample space is $2^{k \choose 2}$. Because the set $S$ is only one specific graph within this set, then there is only one way to choose this graph out of our total set. Therefore, the probability is 

    \[ \Pr[E_S] = \frac{1}{2^{k \choose 2}}\]
\end{solution}

\Part Suppose that $V_1 = \{v_1, \dots, v_{\ell}\}$ and $V_2 = \{w_1, \dots, w_k\}$ are two arbitrary sets of vertices. What conditions must $V_1$ and $V_2$ satisfy in order for $E_{V_1}$ and $E_{V_2}$ to be independent? Prove your answer.

\begin{solution}
    In order for $E_{V_1}$ and $E_{V_2}$ to be independent, then they must not share and edge. To show that this is true, we consider the equation $\Pr[A \mid B] = \Pr[A]$, which is true if $A$ and $B$ are independent events. 

    Suppose $V_1$ and $V_2$ share an edge. Therefore, the probability of $V_1$ being selected after having $V_2$ being selected will require one less edge to be selected of the remaining edges, and therefore $E_{V_1}$ has a higher probability of occurring given that $E_{V_2}$ already happened. Therefore, $\Pr[E_{V_1} \mid E_{V_2}] \neq \Pr[E_{V_1}]$, and so $E_{V_1}$ and $E_{V_2}$ are not independent.
\end{solution}

\Part Prove that ${n \choose k} \le n^k$. (You might find this useful in part (e))


\begin{solution}
    Consider the expression $n \choose k$. Effectively we are choosing $k$ objects from a list of $n$, without replacement. In other words, we are selecting these $k$ objects without replacement. On the other hand, $n^k$ means that we are choosing these $k$ objects with replacement. What this means is that in $n^k$, we are already counting all the possible ways we could have picked elements wihtout replacement (which is $n \choose k$), but now we've also added the possible ways we could choose $k$ elements \textit{with} replacement. Therefore, $n^k$ must at least be larger than $n \choose k$.
\end{solution}

\Part Prove that the probability that the graph contains a $k$-clique, for $k \geq 4{\log_2 n}+1$, is at most $1/n$.


\begin{solution}
    We know that from part (b), the probability that a given $k$-clique exists is 

    \[ \Pr[E_S] = \frac{1}{2^{k \choose 2}}\] 

    Since there are $n \choose k$ $k$-cliques, then therefore the probability that any $k$-clique is formed is 

    \[ \Pr[k] = \frac{{n \choose k}}{2^{k \choose 2}}\]

    Our goal now is to show that this quantity is at most $\frac{1}{n}$. From part (e), we know that $n \choose k \le n^k$, to simplify the numerator: 

    \begin{align*}
        \frac{{n \choose k}}{2^{k \choose 2}}& \le \frac{n^k}{2^{k (k-1)/2}} = \left(\frac{n}{2^{(n-1)/2}}\right)^k
    \end{align*}

    Since we know that the lowest value of $k$ is $k = 4 \log_2n + 1$, then we also know that 

    \[ \left(\frac{n}{2^{(k-1)/2}}\right)^k \le \left(\frac{n}{2^{(4 \log_2 n+1-1)/2}}\right)^k\]

    Simplifying just the denominator, we see that 

    \[ 2^{(4 \log_2n +1 -1)/2} = 2^{4 \log_2n/2} = (2^{\log_2 n})^2 = n^2\]

    and so therefore 

    \[ \left(\frac{n}{2^{(4 \log_2 n+1-1)/2}}\right)^k = \left(\frac{n}{2^{2\log_2n}}\right) = \left(\frac{n}{n^2}\right)^k = \frac{1}{n^k}\]

    Since $k$ takes on a minimal value of $k = 1$, then we know that this probability is at most $\frac{1}{n}$, and so we are done. $\blacksquare$

\end{solution}
\end{Parts}
\pagebreak
\Question{Symmetric Marbles}
A bag contains 4 red marbles and 4 blue marbles. Leanne and Sylvia play a game where they draw four marbles in total, one by one, uniformly at random, without replacement. Leanne wins if there are more red than blue marbles, and Sylvia wins if there are more blue than red marbles. If there are an equal number of marbles, the game is tied.
\begin{Parts}
    \Part Let $A_1$ be the event that the first marble is red and let $A_2$ be the event that the second marble is red. Are $A_1$ and $A_2$ independent?
    
    \begin{solution}
        Yes, they are independent events. The probability that the first marble is red is 
    \end{solution}
    \Part What is the probability that Leanne wins the game?

    \begin{solution}
        Due to symmetry, the probability that Leanne wins is also the probaiblity that Sylvia wins. Therefore, by law of total probability, we have:

        \[ \Pr[L] + \Pr[S] + \Pr[T] = 1 \] 

        and so therefore we can rearrange this into: 

        \[ \Pr[L] = \frac{1 - \Pr[T]}{2}\]

        where $P(T)$ denotes the probability that they tie. To calculate the probability that they tie, we simply require that they draw two red and two blue marbles each. There are $4 \choose 2$ ways to select when the red marbles are drawn, so there are also that many ways of drawing two reds and two blues. The probality that two reds and two blues are drawn is $\frac 48 \cdot \frac 37 \cdot \frac 46 \cdot \frac 35$, so therefore the total probability they tie is: 

        \[ \Pr[T] = \left(\frac 48 \cdot \frac 37 \cdot \frac 46 \cdot \frac 35\right)\cdot 6 \approx 0.51 = 51\%\]

        Now, to calculate $P(L)$ we now do 

        \[ \Pr[L] = \frac{1 - \Pr[T]}{2} \approx 0.242 = 24.2\%\] 

        using the previous result for $P(T)$. Therefore, Leanne has a 24\% chance of winning this game.
    \end{solution}
    
    \Part Given that Leanne wins the game, what is the probability that all of the marbles were red?

    \begin{solution}
        We can use Bayes' rule. Let $A_1$ be the event that all marbles are red, and $A_2$ be the event that Leanne wins. Therefore, 

        \[ \Pr[A_1 \mid A_2] = \frac{\Pr[A_2 \mid A_1]\Pr[A_1]}{\Pr[A_2]}\]

        We know that $P(A_2 \mid A_1) = 1$, since the probaiblity that Leanne wins given all four marbles are red is certain by the rules of the game. Therefore, 

        \[ \Pr[A_2 \mid A_1] = \frac{\Pr[A_1]}{\Pr[A_2]} = \frac{\frac 48 \cdot \frac 37 \cdot \frac 26 \cdot \frac 15}{\Pr[L]} \approx 0.059 = 5.9\%\] 

        The numerical answers are calculated using the reuslts that we've obtained from before, then using a calculator fo compute their values.
    \end{solution}
\end{Parts}
Now, suppose the bag contains 8 red marbles and 4 blue marbles. Moreover, if there are an equal number of red and blue marbles among the four drawn, Leanne wins if the third marble is red, and Sylvia wins if the third marble is blue. 
\begin{ResumeParts}
    \Part What is the probability that the third marble is red?

    \begin{solution}
        The probability of the third marble being red without knowing what the first two marbles were is the same as the probability of the first marble being red. Therefore, 

        \[ \Pr[\text{first red}] = \frac{8}{12} = \frac 23\]
    \end{solution}   
    \Part Given that there are $k$ red marbles among the four drawn, where $0 \leq k \leq 4$, what is the probability that the third marble is red? Answer in terms of $k$.

    \begin{solution}
        Given that there are $k$ marbles among te four that are drawn, we know that each marble has a $\frac 14$ probability of being in the third slot. Therefore, given $k$ marbles, the probaiblity that the third marble is red given $k$ are red is 
        \[ \Pr[\text{third red} \mid \text{k red}] = \frac k4\] 
    \end{solution}
    
    \Part Given that the third marble is red, what is the probability that Leanne wins the game?

    \begin{solution}
        Given that the third marble is red, Leanne wins in two ways: either she has more red marbles than blue, or they tie and the third marble is red. Therefore, the probability can be written as: 

        \[ \Pr[\text{Leanne wins} \mid \text{third ball is red}] = \frac{\Pr[\text{third ball is red}\mid \text{Leanne wins}] \Pr[\text{tie}]}{\Pr[\text{third ball is red}]}\] 

        The probability that the third marble is red is $\frac{8}{12}$, and the probability that they tie is

        \[ \Pr[T] =  6 \cdot \left(\frac{8}{12} \cdot \frac{7}{11} \cdot \frac{4}{10} \cdot \frac39\right)\]

        Now the probaiblity that the third ball is red given that Leanne wins is the same as asking the probaiblity of the third ball being red given that there are either 3 or 4 reds being drawn. Therefore, the probability of this is $\frac{3}{4} + \frac 44$, using the expression we obtained from part (e). Combining all of these together, we get 

        \[ \Pr[\text{Leanne wins} \mid \text{third ball is red}] = \frac{6 \left(\frac 34 + 1\right)\left(\frac{8}{12} \cdot \frac{7}{11} \cdot \frac{4}{10} \cdot \frac39\right)}{\frac{8}{12}} \approx 89\%\]

        The percentage was calculated using a calculator.


    \end{solution}
    
\end{ResumeParts}
\pagebreak
\Question{PIE Extended}

One interesting result yielded by the Principle of Inclusion and Exclusion (PIE) is that for any events $A_1, A_2, \dots, A_n$ in some probability space,
\[
\sum_{i=1}^n \mathbb{P}\left[A_i\right]
- \sum_{i<j\leq n} \mathbb{P}\left[A_i \cap A_j\right]
+ \sum_{i<j<k\leq n} \mathbb{P}\left[A_i \cap A_j \cap A_k\right]
- \dots
+ (-1)^{n-1} \mathbb{P}\left[A_1 \cap A_2 \cap \dots \cap A_n\right]
\geq 0
\]
(Note the LHS is equal to $\mathbb{P}\left[\bigcup_{i=1}^n A_i\right]$ by PIE, and probability is nonnegative).

Prove that for any events $A_1, A_2, \dots, A_n$ in some probability space,
\[
\sum_{i=1}^n \mathbb{P}\left[A_i\right]
- 2\sum_{i<j\leq n} \mathbb{P}\left[A_i \cap A_j\right]
+ 4\sum_{i<j<k\leq n} \mathbb{P}\left[A_i \cap A_j \cap A_k\right]
- \dots
+ (-2)^{n-1} \mathbb{P}\left[A_1 \cap A_2 \cap \dots \cap A_n\right]
\geq 0
\]

(Hint: consider defining an event $B$ to represent "an odd number of $A_1, \dots, A_n$ occur")

\begin{solution}
    Using the hint, we first consider the event that some number of $A_1, \dots, A_n$ occur, starting with one. Here, we see that any element which is strictly in $A_i$ is counted only once, and so our summation also only gives that it is counted once. 
    
    Now consider the number of times that some $A_i \cap A_j$ is counted. It is counted twice in $\sum \Pr[A_i]$, and then counted once in $\sum \Pr[A_i \cap A_j]$. Therefore, our summation gives $2 - 2(1) = 0$.
    
    
    Now consider the number of times $A_i \cap A_j \cap A_k$ is counted. It is counted three times in $\sum \Pr[A_i]$, it is counted ${3 \choose 2} = 3$ times in $\sum \Pr[A_i \cap A_j]$, and once in $\sum \Pr[A_i \cap A_j \cap A_k]$. Therefore, our sum becomes $3 - 2(3) + 4(1) = 1$. 

    We now see a pattern. In general, for an event $S = A_1 \cap A_2 \cap \cdots \cap A_k$, it is counted ${k \choose 1} = k$ times in $\sum \Pr[A_i]$, $k \choose 2$ times in $\sum \Pr[A_i \cap A_j]$ and $k \choose m$ times in $\sum \Pr[A_1 \cap A_2 \cap \cdots \cap A_m]$ where $m < k$. Therefore, the number of times that $S$ is counted in our summation, let it be denoted by $N(S)$, is: 

    \[N(S) = m - 2{m \choose 2} + 4 {m \choose 3} - \cdots + (-2)^{m - 1} {m \choose m}\]

    Notice that this form looks incre99bly similar to the binomial theorem for $(1 + x)^n$: 

    \[ (1 + x)^n = 1 + {n \choose 1} x + {n \choose 2} x^2 + \cdots + {n \choose n}x^n\]

    In order to apply it, we can rearrange this to look slightly more sugestive: 


    \begin{align*}
        N(S) &= \frac{1}{2} \left( 2m - 2^2 {m \choose 2} + \cdots + (-2)^m {m \choose m}\right)\\
        &= \frac{1}{2} \left(1 - 1 + 2m - 2^2 {m \choose 2} + \cdots (-2)^m {m \choose m}\right)\\
        &= \frac{1}{2} \left[ 1 -\left(1 - 2m +2^2 {m \choose 2} + \cdots -(-2)^m {m \choose m}\right)\right]\\
        &= \frac 12 \left( 1 - (1 + (-2))^m\right)\\
        &= \frac 12 (1 - (-1)^m)
    \end{align*}

    Now notice something about $N(S)$: when $m$ is even, then we obtain $N(s) = \frac 12 (0^m) = 0$, and when $m$ is odd, then we get $N(s) = \frac 12 (2) = 1$. Therefore we can also rewrite $N(S)$ into the form: 

    \[ N(S) = \begin{cases}
        1 & \text{$m$ odd}\\
        0 & \text{$m$ even}
    \end{cases}\] 

    Therefore, since $N(S)$ can never be negative, then the number of times any event, whether it is even or odd, is never negative, so the final sum total of our counting is always larger than zero, and so we've proven the problem statement. $\blacksquare$
\end{solution}

\pagebreak
\Question{Independent Complements}

Let $\Omega$ be a sample space, and let $A,B \subseteq \Omega$ be two independent events.

{\color{blue}{Because $A$ and $B$ are independent events, then $\Pr[A \cap B] = \Pr[A] \Pr[B]$}. We will also make use of the following identities: 

\begin{align*}
    \overline{(A \cap B)} &= \overline A \cup \overline B\\
    \overline{(A \cup B)} &= \overline A \cap \overline B\\
    A \setminus B &= A \cap \overline B\\
    A \setminus B &= A - A \cap B\\
    A \setminus B &= \overline B \setminus \overline A
\end{align*}
}

\begin{Parts}

\Part Prove or disprove: $\overline{A}$ and $\overline{B}$ must be independent.

\begin{solution}
    To prove or disprove this, then we are asking whether the relation $\Pr[\overline A \cap \overline B] = \Pr[\overline A]\Pr [\overline B]$ is satisfied. Manipulating the right hand side: 

    \begin{align*}
        \Pr[\overline A] \Pr[\overline B] &= (1 - \Pr[A])(1 - \Pr[B])\\
        &= 1 - \Pr[A] - \Pr[B] - \Pr[A]\Pr[B]\\
        &=  1 - \Pr[A] - \Pr[B] - \Pr[A \cap B]\\
        &= 1 - (\Pr[A] + \Pr[B] - \Pr[A \cap B])\\
        &= 1 - \Pr[A \cup B]\\
        &= \Pr[\overline A \cap \overline B]
    \end{align*}

    And so they are independent events, since the relation is true.
\end{solution}

\Part Prove or disprove: $A$ and $\overline{B}$ must be independent.

\begin{solution}
    We now ask whether $\Pr[A \cap \overline B] = \Pr[A] \Pr[\overline B]$ is true. Manipulating the right hand side: 

    \begin{align*}
        \Pr[A] \Pr[\overline B] &= \Pr[A](1 - \Pr[B])\\
        &= \Pr[A] - \Pr[A] \Pr[B]\\
        &= \Pr[A] - \Pr[A \cap B]
    \end{align*}

    From Discussion 9A, we know that $\Pr[A] - \Pr[A \cap B] = \Pr[A \setminus B] = \Pr[A \cap \overline B]$, so the relation is true, and thus they are independent.
\end{solution}

\Part Prove or disprove: $A$ and $\overline{A}$ must be independent.

\begin{solution}
    We aim to prove whether $\Pr[A \cap \overline A] = \Pr[A] \Pr[\overline A]$. Clearly, this is not true, becuase $\Pr[A \cap \overline A] = 0$ (since an element is either in $A$ or not), but $\Pr[A]$ and $\Pr[\overline A]$ do not necessarily have to be zero.
\end{solution}

\Part Prove or disprove: It is possible that $A=B$.

\begin{solution}
    We use the relation that $\Pr[A \cap B] = \Pr[A]\Pr[B]$. If $A = B$, then we know that $A \cap B = A \cap A = A$, so $\Pr[A \cap B] = \Pr[A]$. However, the right hand side of the equation becomes $\Pr[A]\Pr[B] = (\Pr[A])^2$. So therefore, we need to satisfy the requirement that $\Pr[A] = (\Pr[A])^2$, which is only satisfied when $\Pr[A] = 1$. This is a possible condition, so it is possible that $A = B$.
\end{solution}

\end{Parts}
\pagebreak
\Question{Monty Hall's Revenge}

Due to a quirk of the television studio's recruitment process, Monty Hall has
ended up drawing all the contestants for his game show from among the ranks of
former CS70 students. Unfortunately for Monty, the former students' amazing
probability skills have made his cars-and-goats gimmick unprofitable for the
studio. Monty decides to up the stakes by asking his contestants to generalise
to three new situations with a variable number of doors, goats, and cars:

\begin{Parts}
    \Part There are $n$ doors for some $n > 2$. One has a car behind it, and the
        remaining $n-1$ have goats. As in the ordinary Monty Hall problem, Monty
        will reveal one door with a goat behind it after you make your first
        selection. How would switching affect the odds that you select the car?
        (Compute the probability of winning in both scenarios, and compare the results.)

        (\text{Hint:} Think about the size of the sample space for the
        experiment where you \textit{always} switch. How many of those outcomes
        are favorable?)

        \begin{solution}
            Let $A$ be the probability that we win without switching, and $B$ be the probability that we win when we switch. The probability that we win without switching is the same as the probability that we selected the right door. Therefore, 

            \[ \Pr[A] = \frac{1}{n}\]

            The probability of event $B$ is the probability that the door we selected at first is a goat, then we switch to a car. There is an $\frac{n-1}{n}$ chance of selecting the goat, then after opening one door there are $n - 1 - 2$ doors that you could switch to, one of which has the car. Then, all we have to do is multiply these two occurrences. Therefore: 

            \[ \Pr[B] = \frac{n-1}{n} \cdot \frac{1}{n-2}\] 

            We can look at this a slightly different way: 

            \[ \Pr[B] = \frac{1}{n} \cdot \frac{n-1}{n-2} = \Pr[A] \cdot \frac{n-1}{n-2}\]

            so we have a marginally better chance of winning if we switch, where the odds change less and less as $n$ grows large.
        \end{solution}

    \Part Again there are $n > 2$ doors, one with a car and $n-1$ with goats, but
        this time Monty will reveal $n-2$ doors with goats behind them instead
        of just one. How does switching affect the odds of winning in this
        modified scenario?

        \begin{solution}
            The probaility of event $A$ occurring is the same: $\frac 1n$. However, the probability that we win when we switch is now: 

            \[ \Pr[B] = \frac{n-1}{n} \cdot \frac{n-2}{n-2} = \frac{n-1}{n}\] 

            And so we are significantly more likely to win if we switch, with the odds reaching almost certaintly for large $n$.
        \end{solution}
    \Part Finally, imagine there are $k<n-1$ cars and $n-k$ goats behind the
        $n>2$ doors. After you make your first pick, Monty will reveal $j<n-k$
        doors with goats. What values of $j, k$ maximize the relative
        improvement in your odds of winning if you choose to switch? (i.e. what
        $j, k$ maximizes the ratio between your odds of winning when you switch,
        and your odds of winning when you do not switch?)

        \begin{solution}
            The odds that we win when we don't switch are now if we selected one of the $k$ cars from the original $n$ doors. Therefore, 

            \[ \Pr[A] = \frac{k}{n}\] 

            Alternatively, the odds that we win after switching can be split up into two cases: if we chose a goat on our first selection then switch to a car, or if we chose a car then switch to another car. Therefore, we can write the probability of winning $\Pr[B]$ as: 

            \[ \Pr[B] = \Pr[G] \cdot \Pr[W \mid G] + \Pr[C] \cdot \Pr[W\mid C]\]

            where $W$ denotes the event that we win. The probability of $\Pr[G] = \frac{n-k}{n}$ since there are $n-k$ goats. Given that we chose a goat, then therefore there are $k$ cars left in the remaining $n - j - 1$ doors. Therefore, the probability of winning given that we chose a goat is $\Pr[W \mid G] = \frac{k}{n - j - 1}$.

            Now for the second part of of this expression. The probability that we selected a car at first is $\Pr[C] = \frac kn$, and the probability that we choose another car from the remaining $n - j - 1$ doors is $\Pr[W\mid C] = k -1$, since there are only $k-1$ cars left to choose from. Therefore, our total probaiblity of winning if we switch is


            \[ \Pr[B] = \frac{n-k}{n} \cdot \frac{k}{n -j - 1} + \frac{k}{n} \cdot \frac{k-1}{n - j - 1} = \frac{k(n-1)}{n(n - j - 1)} \] 

            Notice again that we can now derive the relation 

            \[\Pr[B] =  \Pr[A] \cdot \frac{n-1}{n - j - 1}\]

            meaning that in reality the probaiblity of winning when switching is only dependent on the number of doors Monty chooses to open. To maximize the odds of switching, then, we just require this fraction to be as large as we can get, which means picking the maximal value of $j = n - k - 1$.
               
            As an aside, one interesting thing to note is that the odds of winning if we switch are at least as good as not switching, since the fraction $\frac{n - 1}{n - j - 1} \ge 1$ for any $j$ (with equality at $j = 0$), so we should always switch, regardless of how many doors Monty chooses to open!


        \end{solution}
\end{Parts}
\pagebreak
\Question{(Un)conditional (In)equalities}

Let us consider a sample space $\Omega = \{\omega_1, \dots, \omega_N\}$ of size $N>2$ and two probability functions $\Pr_1$ and $\Pr_2$ on it. That is, we have two probability spaces: $(\Omega, \Pr_1)$ and $(\Omega, \Pr_2)$.

\begin{enumerate}[(a)]
    \item Suppose that for every subset $A\subseteq \Omega$ of size $|A| = 2$ and for every outcome $\omega\in\Omega,$ it is true that $\Pr_1[\omega \mid A] = \Pr_2[\omega \mid A]$. 

        \begin{enumerate}[(i)]
            \item Let $A = \{\omega_i, \omega_j\}$ for some $i, j \in \{1, \ldots, N\}$. What is the relationship between $\frac{\Pr_1[\omega_i]}{\Pr_1[\omega_j]}$ and $\frac{\Pr_2[\omega_i]}{\Pr_2[\omega_j]}$?
            
            \begin{solution}
                By Bayes' rule, we have 

                \begin{align*}
                    \Pr_1[\omega \mid A] &=\frac{\Pr_1[A \mid \omega] \cdot \Pr_1[\omega]}{\Pr [A]}\\
                    \Pr_2[\omega \mid B] &= \frac{\Pr_2[A \mid \omega] \cdot \Pr_2[\omega]}{\Pr[A]}
                \end{align*}

                Now we know that $\Pr_1[A \mid \omega] = \Pr_2[A \mid \omega] = 1$ for all $\omega$ since $\omega$ was determined after having selected $A$, so we now obtain the relation 

                \begin{equation}\label{relation}
                     \frac{\Pr_1[\omega]}{\Pr_1[A]} = \frac{\Pr_2[\omega]}{\Pr_2[A]}
                \end{equation}

                Since this equation is true for both $\omega_i$ and $\omega_j$, then we get: 

                \begin{align*}
                    \frac{\Pr_1[\omega_i]}{\Pr_1[A]} &= \frac{\Pr_2[\omega_i]}{\Pr_2[A]}\\
                    \frac{\Pr_1[\omega_j]}{\Pr_1[A]} &= \frac{\Pr_2[\omega_j]}{\Pr_2[A]}
                \end{align*}

                And so we can divide these two equations out to obtain 

                \[ \frac{\Pr_1[\omega_i]}{\Pr_1[\omega_j]} = \frac{\Pr_2[\omega_i]}{\Pr_2[\omega_j]}\] 

                whihc is the relation we want.


            \end{solution}

            \item Is it necessarily true that $\Pr_1[\omega] = \Pr_2[\omega]$ for all $\omega\in\Omega$? That is, if $\Pr_1$ and $\Pr_2$ are equal conditional on events of size $2$, are they equal unconditionally? (\emph{Hint}: Remember that probabilities must add up to $1$.)
            
            \begin{solution}
                By the law of total probability, we have that $\sum_i \Pr_1[\omega_i] = 1$ and $\sum_i \Pr_2[\omega_i] = 1$. Then, we can write the relations: 

                \begin{align*}
                    \frac{1}{\Pr_1[\omega_j]} \sum_i \Pr_1[\omega_i] &= \sum_i \frac{\Pr_1[\omega_i]}{\Pr_1[\omega_j]}\\
                    \frac{1}{\Pr_2[\omega_j]} \sum_i \Pr_2[\omega_i] &= \sum_i \frac{\Pr_2[\omega_i]}{\Pr_2[\omega_j]}
                \end{align*}

                And since the right hand side is equal for every pair of $\omega_i$ and $\omega_j$ then we arrive at the result of $\Pr_1[\omega] = \Pr_2[\omega]$ for every $\omega \in \Omega$.

                % Given the result we obtained in the previous solution, it's not necessarily true that $\Pr_1[A] = \Pr_2[A]$, and so therefore $\Pr_1[\omega]$ is not necessarily equal to $\Pr_2[\omega]$. Another way to see this is the fact that we can arrange equation \ref{relation} into 

                % \[ \frac{\Pr_1[\omega]}{\Pr_2[\omega]} = \frac{\Pr_1[A]}{\Pr_2[A]}\]

                % And since the right hand side is not necessarily equal to 1 (since $\Pr_1[A]$ doesn't have to be equal to $\Pr_2[A]$), then the left hand side doesn't have to either, so thus $\Pr_1[\omega]$ is not necessarily equal to $\Pr_2[\omega]$.
            \end{solution}
        \end{enumerate}

    \item Suppose that for every subset $A\subseteq \Omega$ of size $|A| = k$, where $k$ is some fixed element in $\{2, \dots, N\}$ and for every outcome $\omega\in\Omega,$ it is true that $\Pr_1[\omega \mid A] = \Pr_2[ \omega \mid A]$. Is it necessarily true that $\Pr_1[\omega] = \Pr_2[\omega]$ for all $\omega\in\Omega$? (\emph{Hint}: Use part (a).)
    
    \begin{solution}
        In part (a), we haven't really specified the size of $A$, so the relation that we obtained that $\Pr_1[\omega] = \Pr_2[\omega]$ actually holds for any size $|A|$, so therefore this is always true.
    \end{solution}
\end{enumerate}

For the following two parts, assume that $\Omega = \left\{(a_1, \dots, a_k) \mid \sum_{j=1}^k a_j = n\right\}$ is the set of configurations of $n$ balls into $k$ labeled bins, and let $\Pr_1$ be the probabilities assigned to these configurations by throwing the balls independently one after another and they will land into any of the $k$ bins uniformly at random, and let $\Pr_2$ be the probabilities assigned to these configurations by uniformly sampling one of these configurations.

As an example, suppose $k = 6$ and $n = 2$. $\mathbb{P}_1$ is equivalent to rolling 2 six-sided dice, and letting $a_i$ be the number of $i$'s that appear. $\mathbb{P}_2$ is equivalent to sampling uniformly from all unordered pairs $(i, j)$ with $1 \leq i, j \leq 6$. 

\begin{enumerate}[(a)]
    \setcounter{enumi}{2}
    \item Let $A$ be the event that all $n$ balls are in exactly one bin. 

        \begin{enumerate}[(i)]
            \item What are $\Pr_1\left[ \omega \mid A \right]$ and $\Pr_2\left[ \omega \mid A \right]$ for any $\omega\in A$? 

            \begin{solution}
                We can write $\Pr_1[\omega \mid A]$ into: 

                \[ \Pr_1[\omega \mid A] = \frac{\Pr_1[\omega \cap A]}{\Pr_1[A]}\]

                The probability that all the balls land in one bin $\Pr_1[A] = \frac{1}{k^{n-1}}$, since the first ball doesn't matter. However, the probability that all the balls land in a \textit{specific} bin, expressed by $\Pr_1[\omega \cap A]$ is $\frac{1}{k^n}$ because now the first ball does matter. Therefore, 

                \[ \Pr_1[\omega \mid A] = \frac{\frac{1}{k^n}}{\frac{1}{k^{n-1}}} = \frac{1}{k}\] 

                Similarly, we can rewrite $\Pr_2[\omega \mid A]$ as: 

                \[ \Pr_2[\omega \mid A] = \frac{\Pr_2[\omega \cap A]}{\Pr_2[A]}\]

                Again, the probability of selecting an $\omega$ which represents all balls in one bin is $\frac{k}{|\Omega|}$, since there are $k$ ways to do so. However, the probability of selecting that specific $\omega$ which represents $A$ is $\frac{1}{|\Omega|}$, since there is only one such $\omega$ that corresponds to $A$. Therefore 

                \[ \Pr_2[\omega \mid A] = \frac{\frac{1}{|\Omega|}}{\frac{k}{|\Omega}} = \frac{1}{k}\] 
            \end{solution}
            \item Repeat part (i) for $\omega\in\Omega\setminus A$.
            
            \begin{solution}
                If $\omega \in \Omega \setminus A$, then there is no such $\omega$ which represents all balls being placed in one bin, regardless of the probability distribution we choose, so therefore 

                \[ \Pr_1[\omega \mid A] = \Pr_2[\omega \mid A] = 0\]
            \end{solution}
            \item Is it true that $\Pr_1[\omega] = \Pr_2[\omega]$ for all $\omega\in\Omega$?
            
            \begin{solution}
                No. Consider $\omega$ be the event that all the balls go into a specific bin. Then, $\Pr_2[\Omega] = \frac{1}{|\Omega|}$ since there is only one such omega which we are picking, but $\Pr_1[\omega] = \frac{1}{k^n}$, since we force all the balls to go into one specific bin. However, the statement $|\Omega| = {n + k - 1 \choose k - 1} \neq k^n$ is not always true, so $\Pr_1[\omega] \neq \Pr_2[\omega]$ for all $\omega \in \Omega$.
            \end{solution}
        \end{enumerate}

    \item For the special case of $n=9$ and $k=3$, provide two outcomes $B$ and $C$, so that $\Pr_1[B] < \Pr_2[B]$ and $\Pr_1[C] > \Pr_2[C]$. Provide justification.
    
    \begin{solution}
        First, we calculate the size of the sample space. There are 9 balls going into 3 bins, so using stars and bars we get that $|\Omega| = 55$. 

        First, let $B$ be the event that all the balls go into the first bin. Therefore, we let $\omega = (9, 0, 0)$. Because $\Pr_2[\omega]$ is a uniform sampling, than $\Pr_2[B] = \frac{1}{55} \approx 0.018\%$. 

        Now, the probability that we throw nine balls and have all of them land into bin 1 is 

        \[ \Pr_1[B] = \left(\frac{1}{3}\right)^9 \approx 0.005\%\]

        which is significantly smaller than $\Pr_2[B]$. 

        Now let $C$ be the event that at least one ball goes into the first bin. For $\Pr_2[C]$, this is the same as taking one ball and placing it into bin 1, then asking how many ways there are to distribute the remaining 8. Now there are 8 balls and the same 3 bins, so using stars and bars we get $\Pr_2[C] = \frac{28}{55} \approx 50.9 \%$. 

        Now let's look at $\Pr_1[C]$. The probability that at least one ball lands in bin 1 is the same as $1 - \Pr_2[\text{no balls landing in bin 1}]$. The probability that no balls land in bin 1 is $\left(\frac{2}{3}\right)^9$, since we want to avoid bin 1 for all balls. Therefore, 

        \[ \Pr_1[C] = 1 - \left(\frac{2}{3}\right)^9 \approx 97\%\]

        which is much larger than $\Pr_2[C]$. $\blacksquare$
    \end{solution}
\end{enumerate}

\end{document}
