\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Examples of Machine Learning}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}MNIST}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Machine Learning Approach}{1}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Small aside on training error}{2}{subsubsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}How to make nonlinear decision boundaries?}{2}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Neural Networks}{3}{subsection.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Training a Neural Network}{3}{subsection.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Maximum Likelihood Estimation}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Optimal Classifier}{4}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Error, Validation and Cross-Validation}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Maximum Likelihood Estimation (MLE)}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Quick aside on RVs}{5}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}MLE Setup}{6}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}MLE Properteis}{6}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Univariate Gaussian Example}{6}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Multivariate Gaussians}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}MLE for Multinomial Distribution}{7}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Multivariate Gaussians}{8}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Univariate Gaussians}{9}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Understanding the Covariance Matrix}{9}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Review of Expectations, Variance, Covariance}{9}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Return to MVG}{10}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Diagonalizing a Matrix}{11}{subsection.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Linear Regression}{11}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Regression}{11}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Linear Regression}{11}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Specific Linear Regression}{12}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Linear Regression II}{13}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Intuition for infinite solutions}{13}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}L2 Regularized Linear Regression}{14}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}MAP Estimation}{14}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Lasso regression}{15}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Classification: Generative and Discriminative}{15}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Bayes' Rule}{16}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Ways of Building Classifiers}{17}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Logistic Regression}{17}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Modeling the Posterior Probability Distribution}{17}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Logistic Regression \& Neural Networks}{18}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Multi-Class Classification}{18}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Discriminative Learning}{18}{subsection.7.2}\protected@file@percent }
\newlabel{lec6}{{1}{19}{Discriminative Learning}{equation.7.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Gradient Descent and Backpropagation}{19}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Single-Layer Neural Networks}{19}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Two-Layer Neural Networks}{20}{subsection.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Gradient Descent}{20}{subsection.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Stochastic Gradient Descent}{21}{subsection.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Backpropagation and Gradient Descent II}{22}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Summary of Previous Lecture}{22}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Loss for \( K \)-classification}{23}{subsection.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Generalized Loss}{24}{subsection.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Backpropagation}{24}{subsection.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}CNNs, ResNets, Batch Normalization}{25}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Summary of Last Lecture}{25}{subsection.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Convolutional Neural Networks (CNN)}{25}{subsection.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.1}Invariance and Equivariance}{25}{subsubsection.10.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.2}Structure of a CNN}{26}{subsubsection.10.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}ResNets}{27}{subsection.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Batch Normalization}{27}{subsection.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}Recurrent NNs, Attention \& Transformers}{27}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Sequence-to-Sequence Models}{27}{subsection.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}RNN Bottleneck, Attention}{29}{subsection.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}Transformers}{30}{subsection.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}Dimensionality Reduction, PCA}{32}{section.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}Dimensionality Reduction}{32}{subsection.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}Principal Component Analysis (PCA)}{32}{subsection.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3}Singular Value Decomposition (SVD)}{33}{subsection.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13}t-SNE}{33}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1}Neighborhood Embedding (NE)}{34}{subsection.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2}Stochastic NE (SNE)}{34}{subsection.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14}Clustering}{35}{section.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1}Approaches to Clustering}{35}{subsection.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2}Aside: Distances, metrics}{35}{subsection.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3}\( k \)-means}{35}{subsection.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4}Gradient Descent}{36}{subsection.14.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5}Weaknesses of \( k \)-means}{37}{subsection.14.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6}Soft \( k \)-means}{37}{subsection.14.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.7}Mixture of Gaussians}{38}{subsection.14.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15}Nearest Neighbor and Metric Learning}{38}{section.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.1}Parametric vs. Non-Parametric Models}{38}{subsection.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2}KNN Classifier}{39}{subsection.15.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.3}KNN Generative Classifier}{39}{subsection.15.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4}Pros and Cons of KNN}{39}{subsection.15.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.5}Manifold Hypothesis}{40}{subsection.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16}Multiway Classification, Decision Theory, Model Evaluation}{41}{section.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.1}Choosing between classifiers}{41}{subsection.16.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.2}False Positives, False Negatives, etc.}{41}{subsection.16.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.3}Making ROC Curves}{42}{subsection.16.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.4}Models with AUC}{43}{subsection.16.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.5}Training Classifiers}{43}{subsection.16.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {17}Decision Trees, Ensemble Approaches}{43}{section.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.1}Structure}{43}{subsection.17.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.2}Building Decision Trees}{44}{subsection.17.2}\protected@file@percent }
\gdef \@abspage@last{45}
